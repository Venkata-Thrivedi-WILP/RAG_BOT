{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd126ec4",
   "metadata": {},
   "source": [
    "# Summary of Notebook\n",
    "\n",
    "This notebook processes OpenAPI specifications into structured text documents for use in a Retrieval Augmented Generation (RAG) system. It follows these steps:\n",
    "\n",
    "1. **Data Acquisition**:\n",
    "   - Reads a CSV file containing API names and their corresponding OpenAPI specification URLs\n",
    "   - Downloads YAML specification files from these URLs\n",
    "   - Stores the raw YAML files in a local directory\n",
    "\n",
    "2. **Format Conversion**:\n",
    "   - Parses the YAML files into Python objects\n",
    "   - Converts these objects to JSON format\n",
    "   - Saves the JSON files for further processing\n",
    "\n",
    "3. **Specification Processing**:\n",
    "   - Extracts detailed information about each API endpoint:\n",
    "     - Basic information (path, method, summary)\n",
    "     - Parameters and their descriptions\n",
    "     - Request body schemas and examples\n",
    "     - Response formats and examples\n",
    "     - Security requirements\n",
    "\n",
    "4. **RAG-Optimized Formatting**:\n",
    "   - Structures the extracted information in a consistent format\n",
    "   - Cleans HTML from descriptions\n",
    "   - Generates sample JSON for requests and responses\n",
    "   - Creates comprehensive documentation for each endpoint\n",
    "   \n",
    "5. **Output Generation**:\n",
    "   - Saves processed documentation as text files\n",
    "   - Organizes outputs by API category\n",
    "   - Provides summary statistics about the processed endpoints\n",
    "\n",
    "This processed data can then be used as the knowledge base for a RAG system that can answer questions about these APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd91d83",
   "metadata": {},
   "source": [
    "# Data Collector for YAML to JSON Conversion\n",
    "\n",
    "This notebook:\n",
    "1. Reads URLs from the OG_Dataset.csv file\n",
    "2. Downloads YAML files from those URLs\n",
    "3. Converts the YAML files to JSON format\n",
    "4. Processes OpenAPI specifications into structured text documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3817685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import shutil\n",
    "from git import Repo\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01866a4c",
   "metadata": {},
   "source": [
    "## Step 1: Read the CSV file containing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace8f8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 entries in the CSV file:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "URL",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "9d2eb3b3-5326-441e-bdcf-13721eeade4c",
       "rows": [
        [
         "0",
         "PolicyMangement",
         "https://api.stoplight.io/projects/cHJqOjIxMDg3OQ/branches/main/export/openapi/identity_merged_files/PolicyManagement.yaml"
        ],
        [
         "1",
         "UserManagement",
         "https://api.stoplight.io/projects/cHJqOjIxMDg3OQ/branches/main/export/openapi/identity_merged_files/UserManagement.yaml"
        ],
        [
         "2",
         "ApplicationManagement",
         "https://api.stoplight.io/projects/cHJqOjIxMDg3OQ/branches/main/export/openapi/identity_merged_files/ApplicationManagement.yaml"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PolicyMangement</td>\n",
       "      <td>https://api.stoplight.io/projects/cHJqOjIxMDg3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UserManagement</td>\n",
       "      <td>https://api.stoplight.io/projects/cHJqOjIxMDg3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplicationManagement</td>\n",
       "      <td>https://api.stoplight.io/projects/cHJqOjIxMDg3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name                                                URL\n",
       "0        PolicyMangement  https://api.stoplight.io/projects/cHJqOjIxMDg3...\n",
       "1         UserManagement  https://api.stoplight.io/projects/cHJqOjIxMDg3...\n",
       "2  ApplicationManagement  https://api.stoplight.io/projects/cHJqOjIxMDg3..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "csv_path = '/workspaces/RAG_BOT/OG_Dataset.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the CSV contents\n",
    "print(f\"Found {len(df)} entries in the CSV file:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f37a1",
   "metadata": {},
   "source": [
    "## Step 2: Download YAML files and convert to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bd1698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5802/1993582011.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  category = row[0]  # First column is the category name\n",
      "/tmp/ipykernel_5802/1993582011.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  url = row[1]       # Second column is the URL\n",
      "2025-06-11 00:50:59,743 - INFO - Processing PolicyMangement from https://api.stoplight.io/projects/cHJqOjIxMDg3OQ/branches/main/export/openapi/identity_merged_files/PolicyManagement.yaml\n",
      "2025-06-11 00:51:01,644 - INFO - Saved original YAML to /workspaces/RAG_BOT/Data Processor/yaml_files/PolicyMangement.yaml\n",
      "2025-06-11 00:51:01,644 - INFO - Saved original YAML to /workspaces/RAG_BOT/Data Processor/yaml_files/PolicyMangement.yaml\n",
      "2025-06-11 00:51:01,684 - INFO - Saved JSON to /workspaces/RAG_BOT/Data Processor/json_files/PolicyMangement.json\n",
      "2025-06-11 00:51:01,685 - INFO - Processing UserManagement from https://api.stoplight.io/projects/cHJqOjIxMDg3OQ/branches/main/export/openapi/identity_merged_files/UserManagement.yaml\n",
      "2025-06-11 00:51:01,684 - INFO - Saved JSON to /workspaces/RAG_BOT/Data Processor/json_files/PolicyMangement.json\n",
      "2025-06-11 00:51:01,685 - INFO - Processing UserManagement from https://api.stoplight.io/projects/cHJqOjIxMDg3OQ/branches/main/export/openapi/identity_merged_files/UserManagement.yaml\n",
      "2025-06-11 00:51:03,958 - INFO - Saved original YAML to /workspaces/RAG_BOT/Data Processor/yaml_files/UserManagement.yaml\n",
      "2025-06-11 00:51:03,958 - INFO - Saved original YAML to /workspaces/RAG_BOT/Data Processor/yaml_files/UserManagement.yaml\n",
      "2025-06-11 00:51:04,232 - INFO - Saved JSON to /workspaces/RAG_BOT/Data Processor/json_files/UserManagement.json\n",
      "2025-06-11 00:51:04,233 - INFO - Processing ApplicationManagement from https://api.stoplight.io/projects/cHJqOjIxMDg3OQ/branches/main/export/openapi/identity_merged_files/ApplicationManagement.yaml\n",
      "2025-06-11 00:51:04,232 - INFO - Saved JSON to /workspaces/RAG_BOT/Data Processor/json_files/UserManagement.json\n",
      "2025-06-11 00:51:04,233 - INFO - Processing ApplicationManagement from https://api.stoplight.io/projects/cHJqOjIxMDg3OQ/branches/main/export/openapi/identity_merged_files/ApplicationManagement.yaml\n",
      "2025-06-11 00:51:06,200 - INFO - Saved original YAML to /workspaces/RAG_BOT/Data Processor/yaml_files/ApplicationManagement.yaml\n",
      "2025-06-11 00:51:06,200 - INFO - Saved original YAML to /workspaces/RAG_BOT/Data Processor/yaml_files/ApplicationManagement.yaml\n",
      "2025-06-11 00:51:06,389 - INFO - Saved JSON to /workspaces/RAG_BOT/Data Processor/json_files/ApplicationManagement.json\n",
      "2025-06-11 00:51:06,389 - INFO - Saved JSON to /workspaces/RAG_BOT/Data Processor/json_files/ApplicationManagement.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 3 JSON files and 3 YAML files\n"
     ]
    }
   ],
   "source": [
    "# Create output directories if they don't exist\n",
    "output_dir_json = '/workspaces/RAG_BOT/Data Processor/json_files'\n",
    "output_dir_yaml = '/workspaces/RAG_BOT/Data Processor/yaml_files'\n",
    "os.makedirs(output_dir_json, exist_ok=True)\n",
    "os.makedirs(output_dir_yaml, exist_ok=True)\n",
    "\n",
    "# Process each URL\n",
    "json_files = []\n",
    "yaml_files = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        category = row[0]  # First column is the category name\n",
    "        url = row[1]       # Second column is the URL\n",
    "        \n",
    "        logger.info(f\"Processing {category} from {url}\")\n",
    "        \n",
    "        # Download the YAML file\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        \n",
    "        # Save YAML to file\n",
    "        yaml_filename = f\"{category}.yaml\"\n",
    "        yaml_path = os.path.join(output_dir_yaml, yaml_filename)\n",
    "        \n",
    "        with open(yaml_path, 'w') as yaml_file:\n",
    "            yaml_file.write(response.text)\n",
    "        \n",
    "        logger.info(f\"Saved original YAML to {yaml_path}\")\n",
    "        yaml_files.append(yaml_path)\n",
    "        \n",
    "        # Parse YAML content\n",
    "        yaml_content = yaml.safe_load(response.text)\n",
    "        \n",
    "        # Convert to JSON\n",
    "        json_content = json.dumps(yaml_content, indent=2)\n",
    "        \n",
    "        # Save JSON to file\n",
    "        json_filename = f\"{category}.json\"\n",
    "        json_path = os.path.join(output_dir_json, json_filename)\n",
    "        \n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json_file.write(json_content)\n",
    "        \n",
    "        logger.info(f\"Saved JSON to {json_path}\")\n",
    "        json_files.append(json_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {url}: {str(e)}\")\n",
    "\n",
    "print(f\"Successfully processed {len(json_files)} JSON files and {len(yaml_files)} YAML files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fecda",
   "metadata": {},
   "source": [
    "## Step 3: Process OpenAPI Specifications\n",
    "\n",
    "This section processes the OpenAPI JSON files into structured text documents for use in a RAG (Retrieval Augmented Generation) system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7660a",
   "metadata": {},
   "source": [
    "### 3.1 Utility Functions\n",
    "\n",
    "These functions help with loading and processing OpenAPI specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab43ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openapi_spec(file_path):\n",
    "    \"\"\"Load and parse the OpenAPI JSON specification.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def clean_html(text):\n",
    "    \"\"\"Remove HTML tags and clean up formatting.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"No description provided\"\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    clean_text = re.sub(r'<.*?>', ' ', text)\n",
    "    # Normalize whitespace\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    return clean_text.strip()\n",
    "\n",
    "def extract_extension_fields(method_info):\n",
    "    \"\"\"Extract OpenAPI extension fields starting with 'x-'.\"\"\"\n",
    "    extensions = {}\n",
    "    for key, value in method_info.items():\n",
    "        if key.startswith('x-'):\n",
    "            extensions[key] = value\n",
    "    return extensions\n",
    "\n",
    "def resolve_schema_reference(ref_path, openapi_spec):\n",
    "    \"\"\"Resolve a schema reference to its actual schema definition.\"\"\"\n",
    "    if not ref_path.startswith('#/'):\n",
    "        return None  # External references not supported\n",
    "    \n",
    "    # Remove '#/' from the path and split by '/'\n",
    "    path_parts = ref_path.lstrip('#/').split('/')\n",
    "    \n",
    "    # Navigate through the OpenAPI spec to find the referenced schema\n",
    "    current = openapi_spec\n",
    "    for part in path_parts:\n",
    "        if part in current:\n",
    "            current = current[part]\n",
    "        else:\n",
    "            return None  # Reference path not found\n",
    "    \n",
    "    return current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306be49",
   "metadata": {},
   "source": [
    "### 3.2 Schema Processing Functions\n",
    "\n",
    "These functions generate sample JSON and format schema properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa9c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_json(schema, openapi_spec=None, is_root=True):\n",
    "    \"\"\"Generate a sample JSON object from an OpenAPI schema.\"\"\"\n",
    "    if not schema:\n",
    "        return None\n",
    "    \n",
    "    # Handle $ref references\n",
    "    if '$ref' in schema and openapi_spec:\n",
    "        # Resolve the reference to get the actual schema\n",
    "        resolved_schema = resolve_schema_reference(schema['$ref'], openapi_spec)\n",
    "        if resolved_schema:\n",
    "            return generate_sample_json(resolved_schema, openapi_spec, is_root)\n",
    "        return {\"$ref\": schema['$ref']}  # Fallback if resolution fails\n",
    "    \n",
    "    # Handle different schema types\n",
    "    schema_type = schema.get('type')\n",
    "    \n",
    "    if schema_type == 'object':\n",
    "        result = {}\n",
    "        if 'properties' in schema:\n",
    "            for prop_name, prop_schema in schema['properties'].items():\n",
    "                result[prop_name] = generate_sample_json(prop_schema, openapi_spec, False)\n",
    "        return result\n",
    "    \n",
    "    elif schema_type == 'array':\n",
    "        if 'items' in schema:\n",
    "            return [generate_sample_json(schema['items'], openapi_spec, False)]\n",
    "        return []\n",
    "    \n",
    "    elif schema_type == 'string':\n",
    "        return \"string_value\"\n",
    "    \n",
    "    elif schema_type == 'number' or schema_type == 'integer':\n",
    "        return 0\n",
    "    \n",
    "    elif schema_type == 'boolean':\n",
    "        return False\n",
    "    \n",
    "    # If no specific type or unsupported type\n",
    "    return None\n",
    "\n",
    "def format_property(name, details, indent=\"\"):\n",
    "    \"\"\"Format a schema property in a RAG-friendly way.\"\"\"\n",
    "    prop_type = details.get('type', 'undefined')\n",
    "    description = details.get('description', 'No description provided')\n",
    "    description = clean_html(description)\n",
    "    \n",
    "    if description == '{â€¦}':\n",
    "        description = \"Additional nested properties (abbreviated in schema)\"\n",
    "    \n",
    "    return f\"{indent}* {name} ({prop_type}): {description}\"\n",
    "\n",
    "def format_schema_properties(schema, indent_level=0):\n",
    "    \"\"\"Recursively format schema properties.\"\"\"\n",
    "    lines = []\n",
    "    indent = \"  \" * indent_level\n",
    "    \n",
    "    if not schema:\n",
    "        return lines\n",
    "    \n",
    "    if '$ref' in schema:\n",
    "        ref = schema['$ref'].split('/')[-1]\n",
    "        return [f\"{indent}References schema: {ref}\"]\n",
    "    \n",
    "    if 'properties' in schema:\n",
    "        for prop_name, prop_details in schema['properties'].items():\n",
    "            lines.append(format_property(prop_name, prop_details, indent))\n",
    "            \n",
    "            # Handle nested objects\n",
    "            if prop_details.get('type') == 'object' and 'properties' in prop_details:\n",
    "                lines.append(f\"{indent}  Nested properties:\")\n",
    "                for nested_lines in format_schema_properties(prop_details, indent_level + 2):\n",
    "                    lines.append(nested_lines)\n",
    "            \n",
    "            # Handle arrays\n",
    "            if prop_details.get('type') == 'array' and 'items' in prop_details:\n",
    "                lines.append(f\"{indent}  Array items:\")\n",
    "                for nested_lines in format_schema_properties(prop_details['items'], indent_level + 2):\n",
    "                    lines.append(nested_lines)\n",
    "    \n",
    "    if 'required' in schema and schema['required']:\n",
    "        lines.append(f\"{indent}Required fields: {', '.join(schema['required'])}\")\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec81715",
   "metadata": {},
   "source": [
    "### 3.3 Endpoint Formatting Functions\n",
    "\n",
    "These functions format API endpoints into a structured text format for RAG systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7979894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_endpoint(path, method_info, http_method, openapi_spec):\n",
    "    \"\"\"Format a single endpoint into RAG-friendly text.\"\"\"\n",
    "    lines = []\n",
    "    \n",
    "    # Basic endpoint information\n",
    "    title = method_info.get('summary', 'Unnamed Endpoint')\n",
    "    lines.append(f\"ENDPOINT: {title}\")\n",
    "    lines.append(f\"PATH: {path}\")\n",
    "    lines.append(f\"METHOD: {http_method.upper()}\")\n",
    "    \n",
    "    # Tags\n",
    "    if 'tags' in method_info:\n",
    "        lines.append(f\"TAGS: {', '.join(method_info['tags'])}\")\n",
    "    \n",
    "    # Description\n",
    "    if 'description' in method_info:\n",
    "        description = clean_html(method_info['description'])\n",
    "        lines.append(f\"DESCRIPTION: {description}\")\n",
    "    \n",
    "    # Extension fields (metadata)\n",
    "    extensions = extract_extension_fields(method_info)\n",
    "    if extensions:\n",
    "        lines.append(\"METADATA:\")\n",
    "        for ext_key, ext_value in extensions.items():\n",
    "            lines.append(f\"  * {ext_key}: {ext_value}\")\n",
    "    \n",
    "    # Parameters\n",
    "    if 'parameters' in method_info and method_info['parameters']:\n",
    "        lines.append(\"PARAMETERS:\")\n",
    "        for param in method_info['parameters']:\n",
    "            param_name = param.get('name', 'unnamed')\n",
    "            param_in = param.get('in', 'undefined')\n",
    "            param_required = \"Required\" if param.get('required', False) else \"Optional\"\n",
    "            param_description = clean_html(param.get('description', 'No description provided'))\n",
    "            lines.append(f\"  * {param_name} ({param_in}, {param_required}): {param_description}\")\n",
    "    \n",
    "    # Request Body\n",
    "    if 'requestBody' in method_info:\n",
    "        req_body = method_info['requestBody']\n",
    "        req_required = \"Required\" if req_body.get('required', False) else \"Optional\"\n",
    "        lines.append(f\"REQUEST BODY: {req_required}\")\n",
    "        \n",
    "        if 'content' in req_body:\n",
    "            for content_type, content_details in req_body['content'].items():\n",
    "                lines.append(f\"  Content Type: {content_type}\")\n",
    "                \n",
    "                if 'schema' in content_details:\n",
    "                    schema = content_details['schema']\n",
    "                    lines.append(\"  Schema Properties:\")\n",
    "                    lines.extend(format_schema_properties(schema, 2))\n",
    "                    \n",
    "                    # Generate sample request JSON\n",
    "                    sample_json = generate_sample_json(schema, openapi_spec)\n",
    "                    if sample_json:\n",
    "                        lines.append(\"  Sample Request JSON:\")\n",
    "                        lines.append(f\"  ```json\\n  {json.dumps(sample_json, indent=2)}\\n  ```\")\n",
    "    \n",
    "    # Responses\n",
    "    if 'responses' in method_info:\n",
    "        lines.append(\"RESPONSES:\")\n",
    "        for status_code, response_info in method_info['responses'].items():\n",
    "            lines.append(f\"  Status Code: {status_code}\")\n",
    "            description = clean_html(response_info.get('description', 'No description provided'))\n",
    "            lines.append(f\"  Description: {description}\")\n",
    "            \n",
    "            if 'content' in response_info:\n",
    "                for content_type, content_details in response_info['content'].items():\n",
    "                    lines.append(f\"  Content Type: {content_type}\")\n",
    "                    \n",
    "                    if 'schema' in content_details:\n",
    "                        schema = content_details['schema']\n",
    "                        # In the responses section where it handles $ref\n",
    "                        if '$ref' in schema:\n",
    "                            ref_path = schema['$ref']\n",
    "                            schema_name = ref_path.split('/')[-1]\n",
    "                            \n",
    "                            # Get the full schema from components\n",
    "                            full_schema = None\n",
    "                            if ref_path.startswith('#/components/schemas/'):\n",
    "                                schema_name = ref_path.split('/')[-1]\n",
    "                                if 'components' in openapi_spec and 'schemas' in openapi_spec['components'] and schema_name in openapi_spec['components']['schemas']:\n",
    "                                    full_schema = openapi_spec['components']['schemas'][schema_name]\n",
    "                            \n",
    "                            if full_schema:\n",
    "                                lines.append(f\"  Response Schema: {schema_name}\")\n",
    "                                # Add schema description if available\n",
    "                                if 'description' in full_schema:\n",
    "                                    description = clean_html(full_schema.get('description', 'No description provided'))\n",
    "                                    lines.append(f\"  Description: {description}\")\n",
    "                                \n",
    "                                lines.append(\"  Response Body Properties:\")\n",
    "                                lines.extend(format_schema_properties(full_schema, 2))\n",
    "                                \n",
    "                                # Generate sample response JSON\n",
    "                                sample_json = generate_sample_json(full_schema, openapi_spec)\n",
    "                                if sample_json:\n",
    "                                    lines.append(\"  Sample Response JSON:\")\n",
    "                                    lines.append(f\"  ```json\\n  {json.dumps(sample_json, indent=2)}\\n  ```\")\n",
    "                            else:\n",
    "                                # Fallback to just showing the reference if we can't find the schema\n",
    "                                lines.append(f\"  Response Schema: References {schema_name}\")\n",
    "                                resolved_schema = resolve_schema_reference(schema['$ref'], openapi_spec)\n",
    "                                if resolved_schema:\n",
    "                                    lines.append(\"  Response Schema Properties:\")\n",
    "                                    lines.extend(format_schema_properties(resolved_schema, 2))\n",
    "                                    \n",
    "                                    # Generate sample response JSON from resolved schema\n",
    "                                    sample_json = generate_sample_json(resolved_schema, openapi_spec)\n",
    "                                    if sample_json:\n",
    "                                        lines.append(\"  Sample Response JSON:\")\n",
    "                                        lines.append(f\"  ```json\\n  {json.dumps(sample_json, indent=2)}\\n  ```\")\n",
    "    \n",
    "    # Security\n",
    "    if 'security' in method_info:\n",
    "        security_schemes = []\n",
    "        for security_item in method_info['security']:\n",
    "            for scheme, scopes in security_item.items():\n",
    "                security_schemes.append(scheme)\n",
    "        if security_schemes:\n",
    "            lines.append(f\"SECURITY: {', '.join(security_schemes)}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def format_all_endpoints(openapi_spec):\n",
    "    \"\"\"Process all endpoints in the OpenAPI specification.\"\"\"\n",
    "    all_endpoints = []\n",
    "    \n",
    "    # Process each path and method\n",
    "    for path, path_item in openapi_spec.get('paths', {}).items():\n",
    "        for method, method_info in path_item.items():\n",
    "            # Skip non-HTTP methods\n",
    "            if method in ['parameters', 'servers', 'summary', 'description']:\n",
    "                continue\n",
    "                \n",
    "            endpoint_text = format_endpoint(path, method_info, method, openapi_spec)\n",
    "            all_endpoints.append(endpoint_text)\n",
    "            all_endpoints.append(\"--------\" * 10) \n",
    "    \n",
    "    return \"\\n\".join(all_endpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cdada2",
   "metadata": {},
   "source": [
    "### 3.4 Main Processing Function\n",
    "\n",
    "The main function that processes all OpenAPI spec files and generates the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad44c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Process all OpenAPI spec files in the json_files directory.\"\"\"\n",
    "    # Define directories\n",
    "    json_dir = \"./json_files/\"\n",
    "    output_dir = \"../ProcessedData/\"\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get list of JSON files\n",
    "    json_files = [os.path.join(json_dir, f) for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {json_dir}\")\n",
    "        return\n",
    "\n",
    "    # Process each file\n",
    "    endpoint_count = 0\n",
    "\n",
    "    for json_file in json_files:\n",
    "        # Get base filename without extension\n",
    "        base_name = os.path.basename(json_file)\n",
    "        file_name_without_ext = os.path.splitext(base_name)[0]\n",
    "        output_file = os.path.join(output_dir, f\"{file_name_without_ext}.txt\")\n",
    "        \n",
    "        # Process the file\n",
    "        print(f\"Processing {base_name}...\")\n",
    "        api_spec = load_openapi_spec(json_file)\n",
    "        api_text = format_all_endpoints(api_spec)\n",
    "        \n",
    "        # Count endpoints\n",
    "        endpoint_lines = [line for line in api_text.split('\\n') if line.startswith(\"ENDPOINT:\")]\n",
    "        endpoint_count += len(endpoint_lines)\n",
    "        \n",
    "        # Write individual file\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(api_text)\n",
    "        \n",
    "        print(f\"Created {output_file} with {len(endpoint_lines)} endpoints\")\n",
    "\n",
    "    print(f\"Processing complete. {endpoint_count} total endpoints from {len(json_files)} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cedc0ef",
   "metadata": {},
   "source": [
    "## Step 4: Execute the OpenAPI Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c285f91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing UserManagement.json...\n",
      "Created ../ProcessedData/UserManagement.txt with 33 endpoints\n",
      "Processing PolicyMangement.json...\n",
      "Created ../ProcessedData/PolicyMangement.txt with 9 endpoints\n",
      "Processing ApplicationManagement.json...\n",
      "Created ../ProcessedData/ApplicationManagement.txt with 35 endpoints\n",
      "Processing complete. 77 total endpoints from 3 files.\n",
      "Created ../ProcessedData/PolicyMangement.txt with 9 endpoints\n",
      "Processing ApplicationManagement.json...\n",
      "Created ../ProcessedData/ApplicationManagement.txt with 35 endpoints\n",
      "Processing complete. 77 total endpoints from 3 files.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
