{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07ffd7d0",
      "metadata": {},
      "source": [
        "# Embedding Model Comparison for RAG Systems\n",
        "\n",
        "This notebook evaluates and compares different embedding models for Retrieval-Augmented Generation (RAG) systems. We analyze performance metrics like embedding generation time, query response time, and relevance of retrieved documents across different embedding models.\n",
        "\n",
        "## Models Compared\n",
        "- Llama 3.2 (4096 dimensions)\n",
        "- Nomic Embed (768 dimensions)\n",
        "- HuggingFace MiniLM (384 dimensions)\n",
        "\n",
        "## Process Overview\n",
        "1. Load and preprocess documents\n",
        "2. Configure embedding models\n",
        "3. Run test queries\n",
        "4. Evaluate and visualize performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8a211e13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /home/codespace/.python/current/lib/python3.12/site-packages (0.3.25)\n",
            "Requirement already satisfied: langchain_community in /home/codespace/.python/current/lib/python3.12/site-packages (0.3.24)\n",
            "Requirement already satisfied: langchain_ollama in /home/codespace/.python/current/lib/python3.12/site-packages (0.3.3)\n",
            "Requirement already satisfied: langchain_text_splitters in /home/codespace/.python/current/lib/python3.12/site-packages (0.3.8)\n",
            "Requirement already satisfied: langchain_huggingface in /home/codespace/.python/current/lib/python3.12/site-packages (0.3.0)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community) (3.12.9)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /home/codespace/.local/lib/python3.12/site-packages (from langchain_community) (2.2.4)\n",
            "Requirement already satisfied: ollama<1.0.0,>=0.4.8 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_ollama) (0.5.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_huggingface) (0.21.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain_huggingface) (0.32.5)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (2.6.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (24.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from huggingface-hub>=0.30.2->langchain_huggingface) (1.1.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/codespace/.python/current/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /home/codespace/.python/current/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (76.0.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Installing collected packages: safetensors, regex, transformers, sentence-transformers\n",
            "Successfully installed regex-2024.11.6 safetensors-0.5.3 sentence-transformers-4.1.0 transformers-4.52.4\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install required dependencies\n",
        "%pip install langchain langchain_community langchain_ollama langchain_text_splitters langchain_huggingface sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31292038",
      "metadata": {},
      "source": [
        "## Setup and Dependencies\n",
        "\n",
        "Import all required libraries for document loading, text splitting, embedding generation, evaluation, and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3e549031",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "# Langchain imports\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# Configure plot settings\n",
        "plt.rcParams.update({'font.size': 14})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca7f12e",
      "metadata": {},
      "source": [
        "## Document Loading and Processing\n",
        "\n",
        "Load text documents from a directory and split them into smaller, context-specific chunks for embedding and retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cb975cfc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents loaded: 1\n",
            "Documents loaded:\n",
            "[Document(metadata={'source': '/workspaces/RAG_BOT/2. EmbeddingCompairsion/sampledata/ApplicationManagement.txt'}, page_content='ENDPOINT: Get application templates and categories\\nPATH: /SaasManage/GetTemplatesAndCategories\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageGetTemplatesAndCategories\\n  Response Body Properties:\\n    * Result (object): A list of application templates\\n      Nested properties:\\n        * Category (string): Application category\\n        * DisplayName (string): Application template display name\\n        * AppType (string): Application type\\n        * AppTypeDisplayName (string): Display name of application type\\n        * Icon (string): Path of application icon image\\n        * WebAppType (string): Application web-app-type\\n        * Description (string): Application description\\n        * Name (string): Application template name\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"Category\": \"string_value\",\\n    \"DisplayName\": \"string_value\",\\n    \"AppType\": \"string_value\",\\n    \"AppTypeDisplayName\": \"string_value\",\\n    \"Icon\": \"string_value\",\\n    \"WebAppType\": \"string_value\",\\n    \"Description\": \"string_value\",\\n    \"Name\": \"string_value\"\\n  },\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Checks if Application is still available in the catalog.\\nPATH: /SaasManage/IsApplicationAvailableInCatalog\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * appKey (query, Required): No description provided\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageIsApplicationAvailableInCatalog\\n  Response Body Properties:\\n    * Result (object): False if app is not found in tenants application table OR appKey\\'s template is not found in the global catalog. True otherwise\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Import apps from predefined templates\\nPATH: /SaasManage/ImportAppFromTemplate\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: This API retrieves the template and creates an application instance that can be deployed to users. Only system administrators and users with application management rights can invoke this API. Refer guides section https://identity-developer.cyberark.com/docs/manage-access-to-applications-1#create-an-application\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * ID (array): It is the template name of Application configured in the CyberArk Admin Portal. Can provide multiple template names in the array\\n      Array items:\\n    Required fields: ID\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"ID\": [\\n    \"string_value\"\\n  ]\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageImportAppFromTemplate\\n  Response Body Properties:\\n    * Result (object): Return object for a successful API call.\\n      Nested properties:\\n        * ErrorID (string): Error ID if any error is received from the API. By default it is \\'null\\'\\n        * ErrorCode (string): Error code if any error is received from the API. By default it is \\'null\\'\\n        * Exception (string): Exception message if any exception is received from the API. By default it is \\'null\\'\\n        * MessageID (string): Message Id for failure response. By default it is \\'null\\'\\n        * Result (array): Array of below properties.\\n          Array items:\\n            * _RowKey (string): It is the name or Unique ID of the application. It is also known as App key. Ex: 1c585369-b077-44f8-972f-78d0ffd9ac87\\n            * Exception (string): By default Exception will be null, unless there is an actual exception happened in retrieving the response.\\n            * ID (string): It is the template name of Application configured in the CyberArk Admin Portal. Ex: Dropbox\\n            * success (boolean): The success will be true if application is found else it\\'s false.\\n        * InnerExceptions (string): InnerExceptions\\n        * Message (string): Error message for failure response. By default it is \\'null\\'\\n        * success (boolean): The success will be true or false.\\n        * IsSoftError (boolean): SoftError if true indicates this is not actually an exception but an UI warning popup.\\n    * Error (object): Error message text on failure.\\n      Nested properties:\\n        * Invalid_ID (string): This error message is displayed when the invalid Id is provided. Error message: \\'This application has been removed from the application catalog.\\'\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"Exception\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"Result\": [\\n      {\\n        \"_RowKey\": \"string_value\",\\n        \"Exception\": \"string_value\",\\n        \"ID\": \"string_value\",\\n        \"success\": false\\n      }\\n    ],\\n    \"InnerExceptions\": \"string_value\",\\n    \"Message\": \"string_value\",\\n    \"success\": false,\\n    \"IsSoftError\": false\\n  },\\n  \"Error\": {\\n    \"Invalid_ID\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Delete application.\\nPATH: /SaasManage/DeleteApplication\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: Use this API to delete apps added by admin user. The API gets invoked when the admin user wants to delete apps from admin portal.\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * _RowKey (array): Application key.\\n      Array items:\\n    Required fields: _RowKey\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"_RowKey\": [\\n    \"string_value\"\\n  ]\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageDeleteApplication\\n  Response Body Properties:\\n    * Result (object): The below response is received when request is successful.\\n      Nested properties:\\n        * ErrorID (string): Error Id of occured error during api execution.\\n        * ErrorCode (string): Error message of Error occured.\\n        * Exception (string): If any exception has occured.\\n        * MessageID (string): Message id.\\n        * Result (object): This gives array of application keys with success flag.\\n          Nested properties:\\n            * _RowKey (string): Application key.\\n            * success (boolean): Whether the application is deleted or not.\\n        * InnerExceptions (string): Inner Exception, if any, within exception.\\n        * Message (string): Message if any exception.\\n        * success (boolean): Whether the application is deleted or not.\\n        * IsSoftError (string): Error type is soft or not.\\n    * Error (object): This error message is displayed when the application is of portal type.\\n      Nested properties:\\n        * ErrorMessage (string): Application could not be deleted. Applications with type of Portal are system applications.\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"Exception\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"Result\": {\\n      \"_RowKey\": \"string_value\",\\n      \"success\": false\\n    },\\n    \"InnerExceptions\": \"string_value\",\\n    \"Message\": \"string_value\",\\n    \"success\": false,\\n    \"IsSoftError\": \"string_value\"\\n  },\\n  \"Error\": {\\n    \"ErrorMessage\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Get application details\\nPATH: /SaasManage/GetApplication\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: CyberArk Identity maintains a catalog of application templates that facilitate the process of enabling SSO. Invoke this API to retrieve the metadata information/template of the Application. Only system administrator, users with application management rights can invoke this API.\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * _RowKey (query, Required): It is the name or Unique ID of the application created. It is also known as App key. Can fetch the AppKey from the Admin Portal once we add an application. Can also fetch the RowKey using RedRock query. Note: RowKey can be name or App key of the application but cannot be Application Id value for applications like OAuth or OIDC.\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageGetApplication\\n  Response Body Properties:\\n    * Result (object): Return object for a successful API call. The response of the API varies w.r.t type and category of the application. Below mentioned properties are response fields of one such type.\\n      Nested properties:\\n        * Result (object): This API returns Application-related information as the response. Note that the response of the API varies w.r.t type and Category of the Application.\\n          Nested properties:\\n            * LocalizationMappings (array): These Mappings bring all the language localization capabilities.\\n              Array items:\\n                * Modified (boolean): It is set to true if any mappings are modified. Else false. By default, it is false.\\n                * Default (string): It is set to true if there any default mappings. Else false. By default, it is false.\\n                * Code (string): It is the code used to identify the language.\\n                * Description (string): It is the description about the application in the specified language.\\n                * Name (string): The Application\\'s name in the specified language. Example: User Portal is \\'Portail utilisateur\\' in french\\n            * CertificateSubjectName (string): This is the Application\\'s subject name of the certificate. It is specific to the tenant. Ex: CN=ABC0000 Application Signing Certificate\\n            * Icon (string): It is the absolute path of the application\\'s icon image. Ex: \\'vfslow/lib/branding/Idaptive/userportal.png\\'\\n            * ACL (boolean): ACL(access control list) is a list of rules that specifies whether users have access to an application or any resource. It is true if the user has access to the Application. Else false.\\n            * UseLoginPwUseScript (string): It specifies whether to use the user\\'s login password with the mapping script or not. By default, it is false\\n            * DefaultAuthProfile (string): It is the default profile extracted from the Auth Challenge Definition. By default, it is \\'AlwaysAllowed.\\'\\n            * AdminTag (string): It is the admin tag provided for the Application. It is the same as the Category of the Application. Ex: Finance\\n            * TemplateName (string): It is the template name of the Application. The templates can be internal as well as for external applications. Ex: Dropbox\\n            * _TableName (string): The Tablename where application-related details are stored. By default, it is \\'application\\'\\n            * Handler (string): The application handler is responsible for processing the request and generating a response. Ex: cloudlib; Centrify.Saas.apphandlers.UserPass\\n            * AdminPasswordIsSet (boolean): This property will be true if the admin password exists. Else false. By default, it is false.\\n            * UserNameStrategy (string): It is the strategy used for mapping username. Possible types of strategies are ADAttribute, Fixed, SetByUser, UseScript, SetByProvisioning, None\\n            * DisplayName (string): It is the display name of the application.\\n            * _STAMP (string): It is the unique Id created when an application is created/added in the database. Ex: fd4e9ee9-a9a8-4433-80fb-51eac4d12824\\n            * UseLoginPwAdAttr (boolean): This property will be true if there is additional authentication for the Application. Else false. Default Value: false\\n            * ShowInUP (string): This property is true, then the App is displayed in the user portal. Else false. By default, it is true.\\n            * AppTypeDisplayName (string): There are different types of applications that you can add and deploy to your users. It is the Application\\'s type display Name. Ex: Web - User Password\\n            * WebAppType (string): It is the type of web application. Like Portal, SAML, OpenIDConnect, OAuth etc.\\n            * UseDefaultSigningCert (boolean): This property will be true if there is a default signing certificate for the Application. Else false. Default Value: true\\n            * _PartitionKey (string): partition key is a unique identifier for the partition within a given table, specified by the PartitionKey property. Ex: ABC0123\\n            * AppType (string): This specifies the type of application like Web, Mobile or Unknown.\\n            * State (string): Specifies the Application\\'s state like whether it is active or not. By default, it is \\'active\\'\\n            * RegistrationMessage (string): It is the Registration message of the Application if any added while creating the Application. By default, it is null.\\n            * ParentDisplayName (string): It is the display name of the parent application. Here parent app is overridden from another app. By default, it is null.\\n            * RegistrationLinkMessage (string): It is the message in the registration link of the Application. By default, it is \\'null\\'\\n            * PortalApp (boolean): It is set to true if the App belongs to CyberArk. By default, it is false.\\n            * Generic (boolean): This property tells Whether the Application is a generic application or not. By default, it is false.\\n            * Description (string): It is the description about the application added.\\n            * AuthChallengeDefinitionId (string): It is the UniqueId which tells the Authentication requirements to launch the app. Ex: 25ec7578-3397-474c-b0d9-f884b98717dd\\n            * UserNameArg (string): InnerExceptions\\n            * PasswordIsSet (boolean): This property will be true f there is a Password set for the Application. Else false. Default Value: false\\n            * Name (string): It is the name of the Application.\\n            * Reference (string): It is the unique Reference Id of the application template.Ex: 36960\\n            * AuthRules (object): Auth rules extracted from the Authentication Challenge Definition.\\n              Nested properties:\\n                * _Value (string): Can be null or empty.\\n                * Enabled (boolean): It is set to true if rule is enabled else false.\\n                * _UniqueKey (string): It is the unique Id of the Authentication rule.\\n                * _Type (string): Ex: RowSet\\n            * Thumbprint (string): It is the thumbprint of Certificate for the application. Ex: C1222EFC3D1A54E47AD227C3CDAAE9F4804C82cd\\n            * _RowKey (string): It is the name or Unique Id of the Application. It is also known as App key. Ex: \\'52d1cec-63b7-4415-b4e0-facacb555d4e\\'\\n            * Category (string): It is the Category which application belongs to. Following are the Categories available. Featured Analytics Collaboration Communication CRM Customer Service DevOps Education ERP Finance Government Health Care HR IT and Administration Marketing News and Research Other Product Management Productivity Project Management Sales Security Social Media Software Development Travel\\n            * Url (string): When we are adding external applications, it\\'s the actual URL of that Application. Ex:https://www.dropbox.com/saml_login\\n        * success (boolean): The success will be true or false\\n    * Error (object): Error message text on failure.\\n      Nested properties:\\n        * Invalid_RowKey (string): This error message is displayed when the invalid rowkey is provided. Error message: \\'Please try again or contact your system administrator for assistance.\\'\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"Result\": {\\n      \"LocalizationMappings\": [\\n        {\\n          \"Modified\": false,\\n          \"Default\": \"string_value\",\\n          \"Code\": \"string_value\",\\n          \"Description\": \"string_value\",\\n          \"Name\": \"string_value\"\\n        }\\n      ],\\n      \"CertificateSubjectName\": \"string_value\",\\n      \"Icon\": \"string_value\",\\n      \"ACL\": false,\\n      \"UseLoginPwUseScript\": \"string_value\",\\n      \"DefaultAuthProfile\": \"string_value\",\\n      \"AdminTag\": \"string_value\",\\n      \"TemplateName\": \"string_value\",\\n      \"_TableName\": \"string_value\",\\n      \"Handler\": \"string_value\",\\n      \"AdminPasswordIsSet\": false,\\n      \"UserNameStrategy\": \"string_value\",\\n      \"DisplayName\": \"string_value\",\\n      \"_STAMP\": \"string_value\",\\n      \"UseLoginPwAdAttr\": false,\\n      \"ShowInUP\": \"string_value\",\\n      \"AppTypeDisplayName\": \"string_value\",\\n      \"WebAppType\": \"string_value\",\\n      \"UseDefaultSigningCert\": false,\\n      \"_PartitionKey\": \"string_value\",\\n      \"AppType\": \"string_value\",\\n      \"State\": \"string_value\",\\n      \"RegistrationMessage\": \"string_value\",\\n      \"ParentDisplayName\": \"string_value\",\\n      \"RegistrationLinkMessage\": \"string_value\",\\n      \"PortalApp\": false,\\n      \"Generic\": false,\\n      \"Description\": \"string_value\",\\n      \"AuthChallengeDefinitionId\": \"string_value\",\\n      \"UserNameArg\": \"string_value\",\\n      \"PasswordIsSet\": false,\\n      \"Name\": \"string_value\",\\n      \"Reference\": \"string_value\",\\n      \"AuthRules\": {\\n        \"_Value\": \"string_value\",\\n        \"Enabled\": false,\\n        \"_UniqueKey\": \"string_value\",\\n        \"_Type\": \"string_value\"\\n      },\\n      \"Thumbprint\": \"string_value\",\\n      \"_RowKey\": \"string_value\",\\n      \"Category\": \"string_value\",\\n      \"Url\": \"string_value\"\\n    },\\n    \"success\": false\\n  },\\n  \"Error\": {\\n    \"Invalid_RowKey\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Clone an existing application.\\nPATH: /SaasManage/CloneAnApplication\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: Use this API to clone admin added app. The API gets invoked when the admin user wants to clone app from admin portal.\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * Key (query, Required): It is the name or Unique ID of the application, also known as App key. Can also fetch the Key using RedRock query. Note: Key can be name or App key of the application but cannot be Application Id value for applications like OAuth or OIDC.\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageCloneAnApplicaton\\n  Response Body Properties:\\n    * Result (object): Returns an object for a successful API call. Below mentioned properties are response fields of one such type.\\n      Nested properties:\\n        * ErrorID (string): Error Id of occured error during api execution.\\n        * ErrorCode (string): Error message of Error occured.\\n        * Exception (string): If any exception has occured.\\n        * MessageID (string): Message id.\\n        * Result (object): This gives new application key and old application ID with success flag.\\n          Nested properties:\\n            * _RowKey (string): The new app key for cloned app.\\n            * ID (string): This is key of existing application.\\n            * success (boolean): whether the apllication is cloned or not.\\n        * InnerExceptions (string): Inner Exception, if any, within exception.\\n        * Message (string): Message if any exception.\\n        * success (boolean): whether the apllication is cloned or not.\\n        * IsSoftError (string): Error type is soft or not.\\n    * Error (object): This error message is displayed when app is either portal or global app or template is not found for clonning.\\n      Nested properties:\\n        * ErrorMessage (string): The application does not support for cloning.\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"Exception\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"Result\": {\\n      \"_RowKey\": \"string_value\",\\n      \"ID\": \"string_value\",\\n      \"success\": false\\n    },\\n    \"InnerExceptions\": \"string_value\",\\n    \"Message\": \"string_value\",\\n    \"success\": false,\\n    \"IsSoftError\": \"string_value\"\\n  },\\n  \"Error\": {\\n    \"ErrorMessage\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Gets the ID of an app from its service name\\nPATH: /SaasManage/GetAppIDByServiceName\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * name (query, Required): service name\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageGetAppIDByServiceName\\n  Response Body Properties:\\n    * Result (object): Resulting object, if any, of the call\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Set application permissions\\nPATH: /SaasManage/SetApplicationPermissions\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: You must be a system administrator or have \\'Grant\\' permission on the resource or have global \\'Grant\\' permission on resources. Invoke this API to set permissions for perticular app.\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * RowKey (string): Application key.\\n    * ID (string): ID of the resource, Set to null for global permissions.\\n    * Grants (object): Array of permissions to be set. Each item must include Principal: User name or role name, PType: User, Role.., Rights: ManageSession, Edit, Delete, Grant, AgentAuth.\\n      Nested properties:\\n        * Rights (string): Permissions: Grant, View, Admin, LimitedAdmin.\\n        * Principal (string): User name or role name.\\n        * Type (string): It is user role when new user is added.\\n        * PrincipalId (string): Uuid of the principal.\\n        * PType (string): Principal type: User, Role etc..\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"RowKey\": \"string_value\",\\n  \"ID\": \"string_value\",\\n  \"Grants\": {\\n    \"Rights\": \"string_value\",\\n    \"Principal\": \"string_value\",\\n    \"Type\": \"string_value\",\\n    \"PrincipalId\": \"string_value\",\\n    \"PType\": \"string_value\"\\n  }\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageSetApplicationPermissions\\n  Response Body Properties:\\n    * Result (object): Returns an object for a successful API call.\\n      Nested properties:\\n        * ErrorID (string): Error Id of occured error during api execution.\\n        * ErrorCode (string): Error message of Error occured.\\n        * Exception (string): If any exception has occured.\\n        * MessageID (string): Message id of message.\\n        * Result (object): This API returns Application-related information as the response. Note that the response of the API varies w.r.t type and Category of the Application.\\n        * InnerExceptions (string): Inner Exception, if any, within exception.\\n        * Message (string): Message if any exception.\\n        * success (boolean): The success will be true or false.\\n        * IsSoftError (string): Error is soft or not.\\n    * Error (object): This error message is displayed when you dont have grant access or writable policy or admin rights.\\n      Nested properties:\\n        * ErrorMessage (string): You are not authorized to perform this operation.Please contact your IT helpdesk.\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"Exception\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"Result\": {},\\n    \"InnerExceptions\": \"string_value\",\\n    \"Message\": \"string_value\",\\n    \"success\": false,\\n    \"IsSoftError\": \"string_value\"\\n  },\\n  \"Error\": {\\n    \"ErrorMessage\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Get Client Secret for an OIDC Web App\\nPATH: /SaasManage/GetOpenIdClientSecret\\nMETHOD: POST\\nTAGS: Application Management, Client Secret\\nDESCRIPTION: - This API securely retrieves the client secret for an OIDC web app. - The response includes the client secret in encrypted form as \\'e\\' if encryption is successful, or in plain text as \\'p\\' if encryption fails.\\nMETADATA:\\n  * x-idap-anon: False\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * OIDCAppKey (string): RowKey of the application.\\n    * PublicKey (string): An RSA-OAEP public key to encrypt the secret.\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"OIDCAppKey\": \"string_value\",\\n  \"PublicKey\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageGetOpenIdClientSecret\\n  Response Body Properties:\\n    * Result (object): Return object for a successful API call.\\n      Nested properties:\\n        * success (boolean): The success status is either true or false.\\n        * Result (object): The result includes the client secret for the application.\\n          Nested properties:\\n            * e (string): The client secret in encrypted format if the encryption is successful.\\n            * p (string): The client secret in plain text format if the encryption is unsuccessful.\\n        * Message (string): Error message for failure response. By default it is \\'null\\'.\\n        * MessageID (string): The message ID for a failure response. By default, it is null.\\n        * IsSoftError (boolean): If true, SoftError indicates a UI warning popup rather than an exception.\\n        * Exception (string): The exception message if an exception is received from the API. By default, it is null.\\n        * ErrorID (string): The error ID if an error occurs. By default, it is null.\\n        * ErrorCode (string): The error code if an error occurs. By default, it is null.\\n        * InnerExceptions (string): InnerExceptions\\n    * Error (object): Error message text on failure.\\n      Nested properties:\\n        * UnAuthorized (string): When the user does not have the required permissions, you will see the error message - You are not authorized to perform this operation. Please contact your IT helpdesk.\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"success\": false,\\n    \"Result\": {\\n      \"e\": \"string_value\",\\n      \"p\": \"string_value\"\\n    },\\n    \"Message\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"IsSoftError\": false,\\n    \"Exception\": \"string_value\",\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"InnerExceptions\": \"string_value\"\\n  },\\n  \"Error\": {\\n    \"UnAuthorized\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Update application.\\nPATH: /SaasManage/UpdateApplicationDE\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: This API is invoked to update several fields related to an application and is also used to assign roles for accessing the applications. Only system administrator, users with application management rights can invoke this API. Refer guides section https://identity-developer.cyberark.com/docs/manage-access-to-applications-1#update-an-application\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * ShowRegistration (boolean): It specifies whether to show registration link or not on the UI. By default it is false.\\n    * _RowKey (string): It is the name or Unique ID of the application created. It is also known as App key. Can fetch the AppKey from the CyberArk Admin Portal once we add an application. Can also fetch the RowKey using RedRock query. Note: RowKey can be name or App key of the application but cannot be Application Id value for applications like OAuth or OIDC. Ex: 52d1cec-63b7-4415-b4e0-facacb555d4e\\n    * Handler (string): The application handler is responsible for processing the request and generating a response. Ex: cloudlib Centrify.Saas.apphandlers.UserPass\\n    * IconUri (string): It is the absolute path of the Application icon.\\n    * Script (string): It is the script used to add complex logic for attribute mappings of SAML response. Applicable only for SAML web based application\\n    * AppRoles (object): It is used to assign or un-assign roles for accessing the application.\\n      Nested properties:\\n        * Publish (array): Array of Roles to be assigned for accessing the application.\\n          Array items:\\n            * RoleType (string): It is the type of role. Ex: PrincipalList\\n            * Role (string): It is the Unique Id of the role. Role name, id and type information can be fetched from the Redrock query. Ex: 447acf32_5bb8_45d5_8649_4f31dd5d888e\\n            * ID (string): It is the Unique Id of the role. Role name, id and type information can be fetched from the Redrock query. Ex: 447acf32_5bb8_45d5_8649_4f31dd5d888e\\n            * Application (string): It is the name or Unique ID of the application created. It is also known as App key.\\n            * Automatic (boolean): Specifies whether the application has been set for automatic installation or not. By default it is true.\\n            * Name (string): It is the name of the Role which needs to be assigned to application.\\n        * UnPublish (array): Array of Roles to be un-assigned for accessing the application.\\n          Array items:\\n            * RoleType (string): It is the type of role.\\n            * Role (string): It is the Unique Id of the role. Role name, id and type information can be fetched from the Redrock query.\\n            * ID (string): It is the Unique Id of the role. Role name, id and type information can be fetched from the Redrock query.\\n            * Application (string): It is the name or Unique ID of the application created. It is also known as App key.\\n            * Automatic (boolean): Automatic\\n            * Name (string): It is the name of the Role which needs to be un-assigned to application.\\n    * SamlAttributes (string): This attributes are applicable only to SAML web based application. By default it is null\\n    * Description (string): It is the description about the application added.\\n    * Name (string): It is the name of the Application.\\n    Required fields: _RowKey\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"ShowRegistration\": false,\\n  \"_RowKey\": \"string_value\",\\n  \"Handler\": \"string_value\",\\n  \"IconUri\": \"string_value\",\\n  \"Script\": \"string_value\",\\n  \"AppRoles\": {\\n    \"Publish\": [\\n      {\\n        \"RoleType\": \"string_value\",\\n        \"Role\": \"string_value\",\\n        \"ID\": \"string_value\",\\n        \"Application\": \"string_value\",\\n        \"Automatic\": false,\\n        \"Name\": \"string_value\"\\n      }\\n    ],\\n    \"UnPublish\": [\\n      {\\n        \"RoleType\": \"string_value\",\\n        \"Role\": \"string_value\",\\n        \"ID\": \"string_value\",\\n        \"Application\": \"string_value\",\\n        \"Automatic\": false,\\n        \"Name\": \"string_value\"\\n      }\\n    ]\\n  },\\n  \"SamlAttributes\": \"string_value\",\\n  \"Description\": \"string_value\",\\n  \"Name\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaasManageUpdateApplicationDE\\n  Response Body Properties:\\n    * Result (object): Return object for a successful API call.\\n      Nested properties:\\n        * ErrorID (string): Error ID if any error is received from the API. By default it is \\'null\\'\\n        * ErrorCode (string): Error code if any error is received from the API. By default it is \\'null\\'\\n        * Exception (string): Exception message if any exception is received from the API. By default it is \\'null\\'\\n        * MessageID (string): Message Id for failure response. By default it is \\'null\\'\\n        * Result (object): Result for the update application request.\\n          Nested properties:\\n            * State (integer): If State is \\'0\\' then application fields are updated as expected.\\n        * InnerExceptions (string): InnerExceptions\\n        * Message (string): Error message for failure response. By default it is \\'null\\'\\n        * success (boolean): The success will be true or false.\\n        * IsSoftError (boolean): SoftError if true indicates this is not actually an exception but an UI warning popup.\\n    * Error (object): Error message text on failure.\\n      Nested properties:\\n        * Invalid_RowKey (string): This error message is displayed when the invalid rowkey is provided. Error message: \\'The application does not exist or has been deleted.\\'\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"Exception\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"Result\": {\\n      \"State\": 0\\n    },\\n    \"InnerExceptions\": \"string_value\",\\n    \"Message\": \"string_value\",\\n    \"success\": false,\\n    \"IsSoftError\": false\\n  },\\n  \"Error\": {\\n    \"Invalid_RowKey\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Create a tag with no apps for the current user.\\nPATH: /UPRest/CreateTagWithNoApp\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * tagname (string): tag name\\n    Required fields: tagname\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"tagname\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Delete a tag\\nPATH: /UPRest/DeleteTag\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * tagname (string): tag name\\n    Required fields: tagname\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"tagname\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestDeleteTag\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Downloads logs for the imported accounts file.\\nPATH: /UPRest/DownloadImportAccountsLogFile\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * fileKey (query, Required): The unique identifier for imported file.\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestDownloadImportAccountsLogFile\\n  Response Body Properties:\\n    * Result (object): File containing logs for imported accounts.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Get an application\\'s data.\\nPATH: /UPRest/GetAppByKey\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nPARAMETERS:\\n  * appkey (query, Required): Application key\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * markAppVisited (string): Should the application be mark as visited.\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"markAppVisited\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestGetAppByKey\\n  Response Body Properties:\\n    * Result (object): Application data\\n      Nested properties:\\n        * Shortcut (boolean): Whether the application has been set for optional installation\\n        * Url (string): Application Url\\n        * AdminTag (string): Application admin tag\\n        * Description (string): Application description\\n        * Category (string): Application category\\n        * Name (string): Application name\\n        * TemplateName (string): Application template name\\n        * PasswordIsSet (boolean): Whether the password has been set\\n        * WebAppType (string): Application web-app-type\\n        * DisplayName (string): Application display name\\n        * UsernameRO (boolean): Whether user name is read-only\\n        * WebAppTypeDisplayName (string): Display name of web-app-type\\n        * AppTypeDisplayName (string): Display name of application type\\n        * Intranet (boolean): Whether the application is an intranet app\\n        * AppType (string): Application type\\n        * AppKey (string): Application key\\n        * Rank (integer): Application rank\\n        * Icon (string): Path of application icon image\\n        * Username (string): Application username\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"Shortcut\": false,\\n    \"Url\": \"string_value\",\\n    \"AdminTag\": \"string_value\",\\n    \"Description\": \"string_value\",\\n    \"Category\": \"string_value\",\\n    \"Name\": \"string_value\",\\n    \"TemplateName\": \"string_value\",\\n    \"PasswordIsSet\": false,\\n    \"WebAppType\": \"string_value\",\\n    \"DisplayName\": \"string_value\",\\n    \"UsernameRO\": false,\\n    \"WebAppTypeDisplayName\": \"string_value\",\\n    \"AppTypeDisplayName\": \"string_value\",\\n    \"Intranet\": false,\\n    \"AppType\": \"string_value\",\\n    \"AppKey\": \"string_value\",\\n    \"Rank\": 0,\\n    \"Icon\": \"string_value\",\\n    \"Username\": \"string_value\"\\n  },\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Returns list of credential providers.\\nPATH: /UPRest/GetCredentialsProviderListForImport\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestGetCredentialsProviderListForImport\\n  Response Body Properties:\\n    * Result (object): List of credential providers.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Returns list of details for recently uploaded files.\\nPATH: /UPRest/GetRecentImportedAccountsFile\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * fileCount (query, Required): The number of recent files.\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestGetRecentImportedAccountsFile\\n  Response Body Properties:\\n    * Result (object): List of details for recently uploaded files.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Get applications for user\\nPATH: /UPRest/GetResultantAppsForUser\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: Invoke this API to retrieve the resultant applications where user has access to. Only system administrator, users with application management rights and user management rights can invoke this API. NOTE: This call caches the list of applications and roles. Personal apps are not included in the result.\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * userUuid (query, Required): The unique ID of the user who is having access to applications should be provided. The unique ID is generated when the user is created or invited.\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestGetResultantAppsForUser\\n  Response Body Properties:\\n    * Result (object): Return object for a successful API call.\\n      Nested properties:\\n        * ErrorID (string): Error ID if any error is received from the API. By default it is \\'null\\'\\n        * ErrorCode (string): Error code if any error is received from the API. By default it is \\'null\\'\\n        * Exception (string): Exception message if any exception is received from the API. By default it is \\'null\\'\\n        * MessageID (string): Message Id for failure response. By default it is \\'null\\'\\n        * Result (object): Result includes Count and Columns definition.\\n          Nested properties:\\n            * ReturnID (string): ReturnID for the successful api call. By default it is null\\n            * Count (integer): It is the number of records that the call returns.\\n            * Columns (array): Array list of definition of all Columns.\\n              Array items:\\n                * TableKey (string): specifies whether column is a key and if so what kind of key it is. It can be primary key or foreign key. Ex: \\'Primary\\'\\n                * Description (string): It is the brief description of the column. Ex: \\'Row Identifier (primary key)\\'\\n                * Name (string): It is the name of the column.\\n                * Format (string): Currently It is not applicable. By default it is null.\\n                * TableName (string): It is the name of the table. By default it is null.\\n                * DDName (string): It is the Data dictionary name of the column. Ex: \\'ID\\'\\n                * DDTitle (string): It is the Data dictionary title of the column. Ex: \\'ID\\'\\n                * Type (string): It is the numeric indicator of the type of data in the column. Ex: \\'12\\'\\n                * IsHidden (boolean): specifies whether column is hidden or not. default: false\\n                * Width (integer): Currently It is not applicable. By default it is 0.\\n                * Title (string): Title of the column. Ex: \\'ID\\'\\n                * ForeignKey (string): specifies whether column holds a foreign key or not. By default it is null.\\n            * Results (object): Results the rows from the table.\\n              Nested properties:\\n                * Shortcut (boolean): Specifies whether the application has been set for optional installation or not. by default it is false.\\n                * Entities (array): Array list of definition of all Columns.\\n                  Array items:\\n                    * IsForeignKey (string): Specifies whether the entity has foreign key or not. By default it is false.\\n                    * Type (string): It is type of the entity. Ex: Application\\n                    * Key (string): Unique Id of the Entity. Ex:\\'cb9b5761-6cfe-45a5-8ecf-ce9fa9e0ff82\\'\\n                * Url (string): When we are adding external applications, it\\'s the actual URL of that Application. Ex:https://www.dropbox.com/saml_login\\n                * BypassLoginMFA (boolean): Specifies whether the application can bypass the login MFA or not. By default it is false.\\n                * Row (string): Row consists of Entities list and Specifies the details about user accessible applications; each entry is a dictionary including \\'Type\\' (User, Role), \\'ID\\' (role/user UUID), and \\'Name\\' (role name or \\'User\\' if user is granted direct access)\\n                * Category (string): It is the Category which application belongs to. Following are the Categories available. Featured Analytics Collaboration Communication CRM Customer Service DevOps Education ERP Finance Government Health Care HR IT and Administration Marketing News and Research Other Product Management Productivity Project Management Sales Security Social Media Software Development Travel\\n                * AdminTag (string): It is the admin tag provided for the Application. It is the same as the Category of the Application. Ex: Finance\\n                * Name (string): It is the name of the Application.\\n                * TemplateName (string): It is the template name of the Application. The templates can be internal as well as for external applications. Ex: Dropbox\\n                * WebAppType (string): It is the type of web application. Like Portal, SAML, OpenIDConnect, OAuth etc.\\n                * PasswordIsSet (boolean): This property will be true f there is a Password set for the Application. Else false. Default Value: false\\n                * CertBasedAuthEnabled (boolean): Specifies whether Certificate based Authentication is enabled or not. By default it is false.\\n                * DisplayName (string): It is the display name of the application.\\n                * RegistrationMessage (string): It is the Registration message of the Application if any configured while creating the Application. By default, it is null.\\n                * AuthChallengeDefinitionId (string): It is the UniqueId which tells the Authentication requirements to launch the app. Ex: 25ec7578-3397-474c-b0d9-f884b98717dd\\n                * DerivedCredsSupported (boolean): Specifies whether any derived credentials are supported or not. By default it is false.\\n                * IsCredsAccessible (boolean): Specifies whether credentials are accessible for the application or not. By default it is false.\\n                * UsernameRO (boolean): specifies whether user name is read-only or not. By default it is false.\\n                * ParentDisplayName (string): It is the display name of the parent application. Here parent app is overridden from another app. By default, it is null.\\n                * WebAppTypeDisplayName (string): It is the Display name of application. Ex: web-application-type\\n                * IsNewApp (boolean): It specifies whether the application is newly added or not.\\n                * RegistrationLinkMessage (string): It is the message in the registration link of the Application. By default, it is \\'null\\'\\n                * AppTypeDisplayName (string): There are different types of applications that you can add and deploy to your users. It is the Application\\'s type display Name. Ex: Web - User Password\\n                * AppType (string): This specifies the type of application like Web, Mobile or Unknown.\\n                * Intranet (boolean): Specifies whether the application is an intranet app or not.\\n                * AppKey (string): It is the Unique ID of the application, also known as app key.\\n                * Automatic (boolean): Specifies whether the application has been set for automatic installation or not. By default it is true.\\n                * Rank (integer): It is the rank of the Application.\\n                * ID (string): It is the Unique ID of the application, also known as app key.\\n                * Icon (string): It is the absolute path of the application\\'s icon image. Ex: https://example.com/vfslow/lib/branding/Idaptive/userportal.png\\n                * Username (string): Username. By default it is null.\\n            * FullCount (integer): It specifies number of tables.\\n            * IsAggregate (boolean): It is an attribute.\\n        * InnerExceptions (string): InnerExceptions\\n        * Message (string): Error message for failure response. By default it is \\'null\\'\\n        * success (boolean): The success will be true or false\\n        * IsSoftError (boolean): SoftError if true indicates this is not actually an exception but an UI warning popup.\\n    * Error (object): Error message text on failure.\\n      Nested properties:\\n        * UnAuthorized (string): This error message is displayed when the invalid user Id is provided or if user does not have rights. Error message: \\'You are not authorized to perform this operation. Please contact your IT helpdesk.\\'\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"Exception\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"Result\": {\\n      \"ReturnID\": \"string_value\",\\n      \"Count\": 0,\\n      \"Columns\": [\\n        {\\n          \"TableKey\": \"string_value\",\\n          \"Description\": \"string_value\",\\n          \"Name\": \"string_value\",\\n          \"Format\": \"string_value\",\\n          \"TableName\": \"string_value\",\\n          \"DDName\": \"string_value\",\\n          \"DDTitle\": \"string_value\",\\n          \"Type\": \"string_value\",\\n          \"IsHidden\": false,\\n          \"Width\": 0,\\n          \"Title\": \"string_value\",\\n          \"ForeignKey\": \"string_value\"\\n        }\\n      ],\\n      \"Results\": {\\n        \"Shortcut\": false,\\n        \"Entities\": [\\n          {\\n            \"IsForeignKey\": \"string_value\",\\n            \"Type\": \"string_value\",\\n            \"Key\": \"string_value\"\\n          }\\n        ],\\n        \"Url\": \"string_value\",\\n        \"BypassLoginMFA\": false,\\n        \"Row\": \"string_value\",\\n        \"Category\": \"string_value\",\\n        \"AdminTag\": \"string_value\",\\n        \"Name\": \"string_value\",\\n        \"TemplateName\": \"string_value\",\\n        \"WebAppType\": \"string_value\",\\n        \"PasswordIsSet\": false,\\n        \"CertBasedAuthEnabled\": false,\\n        \"DisplayName\": \"string_value\",\\n        \"RegistrationMessage\": \"string_value\",\\n        \"AuthChallengeDefinitionId\": \"string_value\",\\n        \"DerivedCredsSupported\": false,\\n        \"IsCredsAccessible\": false,\\n        \"UsernameRO\": false,\\n        \"ParentDisplayName\": \"string_value\",\\n        \"WebAppTypeDisplayName\": \"string_value\",\\n        \"IsNewApp\": false,\\n        \"RegistrationLinkMessage\": \"string_value\",\\n        \"AppTypeDisplayName\": \"string_value\",\\n        \"AppType\": \"string_value\",\\n        \"Intranet\": false,\\n        \"AppKey\": \"string_value\",\\n        \"Automatic\": false,\\n        \"Rank\": 0,\\n        \"ID\": \"string_value\",\\n        \"Icon\": \"string_value\",\\n        \"Username\": \"string_value\"\\n      },\\n      \"FullCount\": 0,\\n      \"IsAggregate\": false\\n    },\\n    \"InnerExceptions\": \"string_value\",\\n    \"Message\": \"string_value\",\\n    \"success\": false,\\n    \"IsSoftError\": false\\n  },\\n  \"Error\": {\\n    \"UnAuthorized\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Get tags for application\\nPATH: /UPRest/GetTagsForApp\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: This API retrieves the tags applied for an application. Tags allow users to organize applications by type. Only system administrators and users with application management rights can invoke this API. Refer guides section https://identity-developer.cyberark.com/docs/manage-applications-for-usersnew#create-user-tags-for-an-application\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * appkey (query, Required): It is the name or Unique ID of the application. Can fetch the AppKey from the Admin Portal once we add an application. Can also fetch the RowKey using RedRock query. Note: RowKey can be name or App key of the application but cannot be Application Id value for applications like OAuth or OIDC.\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestGetTagsForApp\\n  Response Body Properties:\\n    * Result (object): Return object for a successful API call.\\n    * Error (object): Error message text on failure.\\n      Nested properties:\\n        * AppKey_NotProvided (string): This error message is displayed when the invalid rowkey is provided. Error message: \\'Parameter \\'appkey\\' must be specified.\\'\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {\\n    \"AppKey_NotProvided\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Rename a tag\\nPATH: /UPRest/RenameTag\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * newTagname (string): new tag name\\n    * tagname (string): tag name\\n    Required fields: newTagname, tagname\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"newTagname\": \"string_value\",\\n  \"tagname\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Set user credentials for an application.\\nPATH: /UPRest/SetUserCredsForApp\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * Password (string): Application password\\n    * PublicKeyHash (string): SHA256 Hex of the public key used to encrypt the password\\n    * appkey (string): Application key\\n    * Username (string): Application user name\\n    * ConnectorId (string): ID of the connector were a public key used to encrypt exists\\n    Required fields: Password, appkey, Username\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"Password\": \"string_value\",\\n  \"PublicKeyHash\": \"string_value\",\\n  \"appkey\": \"string_value\",\\n  \"Username\": \"string_value\",\\n  \"ConnectorId\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: update captured user application .\\nPATH: /UPRest/UpdateCapturedUserApplication\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * appName (string): Application Name\\n    * appkey (string): Application key\\n    * appDescription (string): Application Description\\n    * notes (string): Application notes\\n    * appUrl (string): Application Url\\n    Required fields: appkey\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"appName\": \"string_value\",\\n  \"appkey\": \"string_value\",\\n  \"appDescription\": \"string_value\",\\n  \"notes\": \"string_value\",\\n  \"appUrl\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestDeleteTag\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Update secured item credentials.\\nPATH: /UPRest/UpdateCredsForSecuredItem\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * Password (string): User password\\n    * CustomFields (string): Custom user fields\\n    * Notes (string): Notes for secured item\\n    * Username (string): Username\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"Password\": \"string_value\",\\n  \"CustomFields\": \"string_value\",\\n  \"Notes\": \"string_value\",\\n  \"Username\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestDeleteTag\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Update personal user application.\\nPATH: /UPRest/UpdatePersonalApplication\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * appName (string): Application Name\\n    * appkey (string): Application key\\n    * appDescription (string): Application Description\\n    * notes (string): Application notes\\n    * appUrl (string): Application Url\\n    Required fields: appkey\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"appName\": \"string_value\",\\n  \"appkey\": \"string_value\",\\n  \"appDescription\": \"string_value\",\\n  \"notes\": \"string_value\",\\n  \"appUrl\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: update user application for the current user.\\nPATH: /UPRest/UpdateUserApplication\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * appkey (string): Application key\\n    * notes (string): Application Notes\\n    Required fields: appkey, notes\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"appkey\": \"string_value\",\\n  \"notes\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Upload personal app icon.\\nPATH: /UPRest/UploadPersonalAppIcon\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * appkey (string): Personal app key\\n    Required fields: appkey\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"appkey\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Upload secured item icon.\\nPATH: /UPRest/UploadSecuredItemIcon\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * sItemkey (string): Name of secured item\\n    Required fields: sItemkey\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"sItemkey\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Add and update application tags for the current user.\\nPATH: /UPRest/UpsertTagsForApp\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * appkey (string): Application key\\n    * tagnames (array): list of tag names\\n      Array items:\\n    Required fields: appkey, tagnames\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"appkey\": \"string_value\",\\n  \"tagnames\": [\\n    \"string_value\"\\n  ]\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Add and update secured item tags for the current user.\\nPATH: /UPRest/UpsertTagsForSecuredItem\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * tagnames (array): list of tag names\\n      Array items:\\n    * itemkey (string): Secured item key\\n    Required fields: tagnames, itemkey\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"tagnames\": [\\n    \"string_value\"\\n  ],\\n  \"itemkey\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestDeleteTag\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Gets all available data for the user portal in one call.\\nPATH: /UPRest/GetUPData\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: This call caches the list of applications but does not cache tag information.\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nPARAMETERS:\\n  * force (query, Required): Whether to use the cache. If set to true, the call does not use the cache.\\n  * username (query, Required): Target user name.\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestGetUPData\\n  Response Body Properties:\\n    * Result (object): A list of applications\\n      Nested properties:\\n        * Shortcut (boolean): Whether the application has been set for optional installation\\n        * _RowKey (string): Application ID\\n        * Url (string): Application Url\\n        * Description (string): Application description\\n        * Category (string): Application category\\n        * AdminTag (string): Application admin tag\\n        * Name (string): Application name\\n        * TemplateName (string): Application template name\\n        * WebAppType (string): Application web-app-type\\n        * PasswordIsSet (boolean): Whether the password has been set\\n        * DisplayName (string): Application display name\\n        * UsernameRO (boolean): Whether user name is read-only\\n        * WebAppTypeDisplayName (string): Display name of web-app-type\\n        * Personal (boolean): Whether the application is a self-service application.\\n        * AppTypeDisplayName (string): Display name of application type\\n        * AppType (string): Application type\\n        * Intranet (boolean): Whether the application is an intranet app\\n        * AppKey (string): Application key\\n        * Automatic (boolean): Whether the application has been set for automatic installation\\n        * Rank (integer): Application rank\\n        * Icon (string): Path of application icon image\\n        * Username (string): Application username\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"Shortcut\": false,\\n    \"_RowKey\": \"string_value\",\\n    \"Url\": \"string_value\",\\n    \"Description\": \"string_value\",\\n    \"Category\": \"string_value\",\\n    \"AdminTag\": \"string_value\",\\n    \"Name\": \"string_value\",\\n    \"TemplateName\": \"string_value\",\\n    \"WebAppType\": \"string_value\",\\n    \"PasswordIsSet\": false,\\n    \"DisplayName\": \"string_value\",\\n    \"UsernameRO\": false,\\n    \"WebAppTypeDisplayName\": \"string_value\",\\n    \"Personal\": false,\\n    \"AppTypeDisplayName\": \"string_value\",\\n    \"AppType\": \"string_value\",\\n    \"Intranet\": false,\\n    \"AppKey\": \"string_value\",\\n    \"Automatic\": false,\\n    \"Rank\": 0,\\n    \"Icon\": \"string_value\",\\n    \"Username\": \"string_value\"\\n  },\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Verify if username provided for personal app or secured item is allowed.\\nPATH: /UPRest/ValidateUsernameIsAllowed\\nMETHOD: POST\\nTAGS: Application Management\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * userName (string): WPM user name\\n    Required fields: userName\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"userName\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestCreateTagWithNoApp\\n  Response Body Properties:\\n    * Result (object): Whether the operation is successful or not.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Get TOTP codes for a Secured Password.\\nPATH: /UPRest/GetTotpCodesForSecuredPassword\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: - Get n TOTP codes for a Secured Password. - The default value for n is 3, but it can be configured. - The response includes the period for TOTP calculation and a list of TOTP tokens in Base64 format.\\nMETADATA:\\n  * x-idap-anon: False\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * sItemkey (string): Secured Item\\'s\\' Unique ID.\\n    * actionType (string): Optional. The action item for audit events includes the type of action (AutoFill, IBECopy, ContextMenuCopy). By default, it is set to \\'null\\'.\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"sItemkey\": \"string_value\",\\n  \"actionType\": \"string_value\"\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestGetTotpCodesForSecuredPassword\\n  Response Body Properties:\\n    * Result (object): Return object for a successful API call.\\n      Nested properties:\\n        * success (boolean): The success status is either true or false.\\n        * Result (object): Result includes TOTP Codes.\\n          Nested properties:\\n            * Period (integer): Verification code validity period.\\n            * TOTPCodes (object): Results the n TOTP codes.Here the n value is 3.\\n              Nested properties:\\n                * 1 (string): First TOTP Code.\\n                * 2 (string): Second TOTP Code.\\n                * 3 (string): Third TOTP Code.\\n            * EpochTimeInSec (integer): The epoch time for TOTP codes is the number of 30-second periods since January 1, 1970, which determines the current TOTP code.\\n        * Message (string): Error message for failure response. By default it is \\'null\\'.\\n        * MessageID (string): Message Id for failure response. By default it is \\'null\\'.\\n        * IsSoftError (boolean): SoftError if true indicates this is not actually an exception but an UI warning popup.\\n        * Exception (string): Exception message if any exception is received from the API. By default it is \\'null\\'.\\n        * ErrorID (string): Error ID if any error is received from the API. By default it is \\'null\\'.\\n        * ErrorCode (string): Error code if any error is received from the API. By default it is \\'null\\'.\\n        * InnerExceptions (string): InnerExceptions\\n    * Error (object): Error message text on failure.\\n      Nested properties:\\n        * UnAuthorized (string): This error message is displayed when user does not have rights. Error message: \\'You are not authorized to perform this operation. Please contact your IT helpdesk.\\'\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"success\": false,\\n    \"Result\": {\\n      \"Period\": 0,\\n      \"TOTPCodes\": {\\n        \"1\": \"string_value\",\\n        \"2\": \"string_value\",\\n        \"3\": \"string_value\"\\n      },\\n      \"EpochTimeInSec\": 0\\n    },\\n    \"Message\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"IsSoftError\": false,\\n    \"Exception\": \"string_value\",\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"InnerExceptions\": \"string_value\"\\n  },\\n  \"Error\": {\\n    \"UnAuthorized\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Set TOTP seed for a secured password.\\nPATH: /UPRest/SaveTotpSeedForSecuredPassword\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: - This API sets the TOTP seed for a secured password. - If you do not provide a value for totpSecret , then the system clears the secret for the secured password.\\nMETADATA:\\n  * x-idap-anon: False\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * sItemkey (string): The Secured Item\\'s Unique ID.\\n    * algorithm (string): The algorithm used for TOTP verification code generation. The default algorithm is SHA1.\\n    * digits (number): This defines the number of verification code digits.\\n    * issuer (string): Issuer of the TOTP authentication key.\\n    * label (string): Label for the TOTP authentication key.\\n    * totpSecret (string): This is the TOTP authentication key secret for an application.\\n    * type (string): Optional. This specifies the type of OTP being used.\\n    * period (number): Verification code validity period. The default validity period is 30 seconds.\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"sItemkey\": \"string_value\",\\n  \"algorithm\": \"string_value\",\\n  \"digits\": 0,\\n  \"issuer\": \"string_value\",\\n  \"label\": \"string_value\",\\n  \"totpSecret\": \"string_value\",\\n  \"type\": \"string_value\",\\n  \"period\": 0\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestSaveTotpSeedForSecuredPassword\\n  Response Body Properties:\\n    * Result (object): Return object for a successful API call.\\n      Nested properties:\\n        * success (boolean): The success status is either true or false.\\n        * Result (object): Result for a response.By default it is \\'null\\'.\\n        * Message (string): Error message for failure response. By default it is \\'null\\'.\\n        * MessageID (string): Message Id for failure response. By default it is \\'null\\'.\\n        * IsSoftError (boolean): SoftError if true indicates this is not actually an exception but an UI warning popup.\\n        * Exception (string): Exception message if any exception is received from the API. By default it is \\'null\\'.\\n        * ErrorID (string): Error ID if any error is received from the API. By default it is \\'null\\'.\\n        * ErrorCode (string): Error code if any error is received from the API. By default it is \\'null\\'.\\n        * InnerExceptions (string): InnerExceptions\\n    * Error (object): Error message text on failure.\\n      Nested properties:\\n        * UnAuthorized (string): This error message is displayed when user does not have rights. Error message: \\'You are not authorized to perform this operation. Please contact your IT helpdesk.\\'\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"success\": false,\\n    \"Result\": {},\\n    \"Message\": \"string_value\",\\n    \"MessageID\": \"string_value\",\\n    \"IsSoftError\": false,\\n    \"Exception\": \"string_value\",\\n    \"ErrorID\": \"string_value\",\\n    \"ErrorCode\": \"string_value\",\\n    \"InnerExceptions\": \"string_value\"\\n  },\\n  \"Error\": {\\n    \"UnAuthorized\": \"string_value\"\\n  }\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Add/Update/Delete files for a Secured Item.\\nPATH: /UPRest/UpRestSaveFilesForSecuredItem\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: This endpoint is called when the user clicks Save to save the file attachment from the User Portal.\\nMETADATA:\\n  * x-idap-anon: False\\n  * x-codegen-request-body-name: payload\\nREQUEST BODY: Required\\n  Content Type: application/json\\n  Schema Properties:\\n    * Metadata (array): Holds file metadata.\\n      Array items:\\n        * Name (string): Filename.\\n        * Id (string): Unique file identifier.\\n        * Hidden (boolean): Enables or disables the file.\\n        * Size (number): File size.\\n    * File (object): File is in the form-data. (Not as a parameter.)\\n    Required fields: File\\n  Sample Request JSON:\\n  ```json\\n  {\\n  \"Metadata\": [\\n    {\\n      \"Name\": \"string_value\",\\n      \"Id\": \"string_value\",\\n      \"Hidden\": false,\\n      \"Size\": 0\\n    }\\n  ],\\n  \"File\": {}\\n}\\n  ```\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: SaveFilesForSecuredItem\\n  Response Body Properties:\\n    * Result (object): Indicates whether the operation is successful.\\n    * Error (object): Error message text on failure, may be null.\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Returns a list of secured files attached to a Secured Item.\\nPATH: /UPRest/GetSecureFiles\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: This endpoint is called when the user clicks on a Secured Item from the User Portal.\\nMETADATA:\\n  * x-idap-anon: False\\nPARAMETERS:\\n  * sItemkey (query, Required): Secured item _RowKye.\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UPRestGetRecentImportedAccountsFile\\n  Response Body Properties:\\n    * Result (object): List of details for recently uploaded files.\\n    * Error (object): Error message text on failure, may be null\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {},\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------\\nENDPOINT: Get consumed storage space for the current user.\\nPATH: /UPRest/UpRestGetConsumedStorageForSecuredItem\\nMETHOD: POST\\nTAGS: Application Management\\nDESCRIPTION: This endpoint is called when clicks to add a Secured Item from the User Portal.\\nMETADATA:\\n  * x-idap-anon: False\\nRESPONSES:\\n  Status Code: 200\\n  Description: API-Result\\n  Content Type: */*\\n  Response Schema: UpRestGetConsumedStorageForSecuredItem\\n  Response Body Properties:\\n    * Result (object): File storage consumed per user.\\n      Nested properties:\\n        * StorageSpaceConsumed (number): Total amount of space consumed per user for file storage.\\n    * Error (object): Error message text on failure, may be null.\\n  Sample Response JSON:\\n  ```json\\n  {\\n  \"Result\": {\\n    \"StorageSpaceConsumed\": 0\\n  },\\n  \"Error\": {}\\n}\\n  ```\\nSECURITY: bearerAuth\\n--------------------------------------------------------------------------------')]\n"
          ]
        }
      ],
      "source": [
        "# Load all text files from the specified directory\n",
        "folder_path = \"/workspaces/RAG_BOT/2. EmbeddingCompairsion/sampledata\"  # Change as needed\n",
        "document_loader = DirectoryLoader(folder_path, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
        "raw_documents = document_loader.load()\n",
        "\n",
        "print(f\"Number of documents loaded: {len(raw_documents)}\")\n",
        "print(\"Documents loaded:\")\n",
        "print(raw_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "312608d6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total split chunks: 35\n"
          ]
        }
      ],
      "source": [
        "# Split each raw document based on dashed line and create sub-documents\n",
        "split_documents = []\n",
        "for doc in raw_documents:\n",
        "    # Use regex to split based on dashed lines like '-----...'\n",
        "    parts = re.split(r'-{5,}', doc.page_content)\n",
        "    for i, part in enumerate(parts):\n",
        "        cleaned_part = part.strip()\n",
        "        if cleaned_part:\n",
        "            split_documents.append(\n",
        "                Document(\n",
        "                    page_content=cleaned_part,\n",
        "                    metadata={\"source\": doc.metadata[\"source\"], \"part\": i + 1}\n",
        "                )\n",
        "            )\n",
        "\n",
        "print(f\"Total split chunks: {len(split_documents)}\")\n",
        "\n",
        "# Prepare documents with consistent metadata for embedding\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=chunk.page_content,\n",
        "        metadata=chunk.metadata\n",
        "    ) for chunk in split_documents\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28937128",
      "metadata": {},
      "source": [
        "## Embedding Models Configuration\n",
        "\n",
        "Configure different embedding models with their respective dimensions for comparative evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e597aa1b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Set up embedding models with dimensions noted\n",
        "embedding_models = {\n",
        "    \"Llama 3.2\": {\n",
        "        \"model\": OllamaEmbeddings(model=\"llama3.2:latest\", base_url=\"http://localhost:11434\"),\n",
        "        \"dimensions\": 4096\n",
        "    },\n",
        "    \"Nomic\": {\n",
        "        \"model\": OllamaEmbeddings(model=\"nomic-embed-text:latest\", base_url=\"http://localhost:11434\"),\n",
        "        \"dimensions\": 768\n",
        "    },\n",
        "    \"HuggingFace (MiniLM)\": {\n",
        "        \"model\": HuggingFaceEmbeddings(model=\"all-MiniLM-L6-v2\"),\n",
        "        \"dimensions\": 384\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "763e9abc",
      "metadata": {},
      "source": [
        "## Test Queries Setup\n",
        "\n",
        "Define test queries to evaluate the performance of different embedding models. These queries will be used to test retrieval effectiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e030bbb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define test queries with known relevant document IDs (if available)\n",
        "test_queries = [\n",
        "    {\"query\": \"how to get a policy?\", \"relevant_docs\": []},  # Add document IDs if you know ground truth\n",
        "    {\"query\": \"What is request body needed for https://{tenant_url}/Policy/SavePolicyBlock3\", \"relevant_docs\": []},\n",
        "    {\"query\": \"delete a policy\", \"relevant_docs\": []}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f66ca0cc",
      "metadata": {},
      "source": [
        "## Evaluation Function\n",
        "\n",
        "Define a function to evaluate embedding models by measuring:\n",
        "1. Embedding generation time\n",
        "2. Query response time\n",
        "3. Relevance of retrieved documents\n",
        "4. Overall performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "58b54f90",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_embedding_model(model_name, embedding_model, documents, test_queries, k=5):\n",
        "    # Time the embedding creation\n",
        "    start_time = time.time()\n",
        "    vector_store = InMemoryVectorStore.from_documents(documents, embedding_model)\n",
        "    embedding_time = time.time() - start_time\n",
        "\n",
        "    results = []\n",
        "    model_metrics = {\n",
        "        \"model\": model_name,\n",
        "        \"embedding_time\": embedding_time,\n",
        "        \"doc_count\": len(vector_store.store),\n",
        "        \"queries\": []\n",
        "    }\n",
        "\n",
        "    # Test each query\n",
        "    for test_case in test_queries:\n",
        "        query = test_case[\"query\"]\n",
        "        print(f\"\\nQuery: '{query}'\")\n",
        "\n",
        "        # Time the query execution\n",
        "        start_time = time.time()\n",
        "        search_results = vector_store.similarity_search_with_score(query, k=k)\n",
        "        query_time = time.time() - start_time\n",
        "\n",
        "        # Extract results and scores\n",
        "        retrieved_docs = []\n",
        "        for i, (doc, score) in enumerate(search_results, start=1):\n",
        "            doc_id = f\"{doc.metadata.get('source', 'unknown')}:{doc.metadata.get('part', 'unknown')}\"\n",
        "            retrieved_docs.append({\n",
        "                \"rank\": i,\n",
        "                \"doc_id\": doc_id,\n",
        "                \"score\": score,\n",
        "                \"content\": doc.page_content[:150] + \"...\" if len(doc.page_content) > 150 else doc.page_content\n",
        "            })\n",
        "            print(f\"  Result {i} (Score: {score}):\")\n",
        "            print(f\"  {doc.page_content[:150]}...\")\n",
        "            print(f\"  {'-' * 40}\")\n",
        "\n",
        "            # Add to full results for dataframe\n",
        "            results.append({\n",
        "                \"model\": model_name,\n",
        "                \"query\": query,\n",
        "                \"rank\": i,\n",
        "                \"score\": score,\n",
        "                \"doc_id\": doc_id,\n",
        "                \"content\": doc.page_content[:150] + \"...\" if len(doc.page_content) > 150 else doc.page_content,\n",
        "                \"query_time\": query_time\n",
        "            })\n",
        "\n",
        "        # Calculate metrics for this query\n",
        "        query_metrics = {\n",
        "            \"query\": query,\n",
        "            \"query_time\": query_time,\n",
        "            \"top_score\": search_results[0][1] if search_results else None,\n",
        "            \"retrieved_docs\": retrieved_docs\n",
        "        }\n",
        "        model_metrics[\"queries\"].append(query_metrics)\n",
        "\n",
        "    return results, model_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d9ec14",
      "metadata": {},
      "source": [
        "## Running Model Evaluations\n",
        "\n",
        "Execute evaluations on all embedding models and gather performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d7a21936",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluating Llama 3.2 (Dimensions: 4096) ===\n"
          ]
        },
        {
          "ename": "ResponseError",
          "evalue": "llama runner process has terminated: signal: terminated (status code: 500)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model_info \u001b[38;5;129;01min\u001b[39;00m embedding_models.items():\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_info[\u001b[33m'\u001b[39m\u001b[33mdimensions\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     results, metrics = \u001b[43mevaluate_embedding_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_queries\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     all_results.extend(results)\n\u001b[32m     14\u001b[39m     all_metrics.append(metrics)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mevaluate_embedding_model\u001b[39m\u001b[34m(model_name, embedding_model, documents, test_queries, k)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_embedding_model\u001b[39m(model_name, embedding_model, documents, test_queries, k=\u001b[32m5\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Time the embedding creation\u001b[39;00m\n\u001b[32m      3\u001b[39m     start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     vector_store = \u001b[43mInMemoryVectorStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     embedding_time = time.time() - start_time\n\u001b[32m      7\u001b[39m     results = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/langchain_core/vectorstores/in_memory.py:567\u001b[39m, in \u001b[36mInMemoryVectorStore.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, **kwargs)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    562\u001b[39m     **kwargs: Any,\n\u001b[32m    563\u001b[39m ) -> InMemoryVectorStore:\n\u001b[32m    564\u001b[39m     store = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m    565\u001b[39m         embedding=embedding,\n\u001b[32m    566\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m     \u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:113\u001b[39m, in \u001b[36mVectorStore.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    110\u001b[39m         \u001b[38;5;66;03m# For backward compatibility\u001b[39;00m\n\u001b[32m    111\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`add_texts` has not been implemented for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/langchain_core/vectorstores/in_memory.py:195\u001b[39m, in \u001b[36mInMemoryVectorStore.add_documents\u001b[39m\u001b[34m(self, documents, ids, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Add documents to the store.\"\"\"\u001b[39;00m\n\u001b[32m    194\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m vectors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids) != \u001b[38;5;28mlen\u001b[39m(texts):\n\u001b[32m    198\u001b[39m     msg = (\n\u001b[32m    199\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mids must be the same length as texts. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    200\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ids and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m texts.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    201\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/langchain_ollama/embeddings.py:265\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    264\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed search docs.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     embedded_docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedded_docs\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/ollama/_client.py:367\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, model, input, truncate, options, keep_alive)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    360\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    361\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    366\u001b[39m ) -> EmbedResponse:\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbedResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/embed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmbedRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/ollama/_client.py:180\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/site-packages/ollama/_client.py:124\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    126\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[31mResponseError\u001b[39m: llama runner process has terminated: signal: terminated (status code: 500)"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "all_results = []\n",
        "all_metrics = []\n",
        "\n",
        "for model_name, model_info in embedding_models.items():\n",
        "    print(f\"\\n=== Evaluating {model_name} (Dimensions: {model_info['dimensions']}) ===\")\n",
        "    results, metrics = evaluate_embedding_model(\n",
        "        model_name,\n",
        "        model_info[\"model\"],\n",
        "        documents,\n",
        "        test_queries\n",
        "    )\n",
        "    all_results.extend(results)\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "# Create DataFrame for analysis\n",
        "results_df = pd.DataFrame(all_results)\n",
        "\n",
        "# Performance Summary Table\n",
        "performance_summary = []\n",
        "for metrics in all_metrics:\n",
        "    model_summary = {\n",
        "        \"model\": metrics[\"model\"],\n",
        "        \"embedding_time\": f\"{metrics['embedding_time']:.2f}s\",\n",
        "        \"dimensions\": embedding_models[metrics[\"model\"]][\"dimensions\"]\n",
        "    }\n",
        "\n",
        "    # Add query-specific metrics\n",
        "    for q_idx, query_metrics in enumerate(metrics[\"queries\"]):\n",
        "        query_name = f\"q{q_idx+1}\"\n",
        "        model_summary[f\"{query_name}_time\"] = f\"{query_metrics['query_time']:.2f}s\"\n",
        "        model_summary[f\"{query_name}_top_score\"] = f\"{query_metrics['top_score']:.4f}\"\n",
        "\n",
        "    performance_summary.append(model_summary)\n",
        "\n",
        "# Display performance summary\n",
        "print(\"\\n=== PERFORMANCE SUMMARY ===\")\n",
        "summary_df = pd.DataFrame(performance_summary)\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ec2966",
      "metadata": {},
      "source": [
        "## Results Visualization\n",
        "\n",
        "Create comprehensive visualizations to compare embedding model performance:\n",
        "1. Score distribution by model\n",
        "2. Query time comparison\n",
        "3. Top scores by query and model\n",
        "4. Correlation between embedding dimensions and performance\n",
        "5. Side-by-side model performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e8346a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a mapping of queries to shorter labels\n",
        "query_labels = {}\n",
        "for i, q in enumerate([q['query'] for q in test_queries]):\n",
        "    query_labels[q] = f'q{i+1}'\n",
        "\n",
        "# Convert DataFrame to use query labels instead of full text\n",
        "results_df_labeled = results_df.copy()\n",
        "results_df_labeled['query_label'] = results_df['query'].map(query_labels)\n",
        "\n",
        "# Create advanced visualizations with larger figure size\n",
        "plt.figure(figsize=(20, 16))\n",
        "\n",
        "# 1. Score distribution by model\n",
        "plt.subplot(2, 2, 1)\n",
        "for model in results_df['model'].unique():\n",
        "    model_scores = results_df[results_df['model'] == model]['score']\n",
        "    plt.hist(model_scores, alpha=0.6, label=model, bins=15)\n",
        "plt.xlabel('Similarity Score (lower is better)', fontsize=16)\n",
        "plt.ylabel('Frequency', fontsize=16)\n",
        "plt.title('Score Distribution by Model', fontsize=18, fontweight='bold')\n",
        "plt.legend(fontsize=14)\n",
        "\n",
        "# 2. Query time comparison\n",
        "plt.subplot(2, 2, 2)\n",
        "query_times = results_df.groupby(['model', 'query'])['query_time'].first().reset_index()\n",
        "# Add query labels\n",
        "query_times['query_label'] = query_times['query'].map(query_labels)\n",
        "pivot_times = query_times.pivot(index='query_label', columns='model', values='query_time')\n",
        "pivot_times.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Query Response Time by Model', fontsize=18, fontweight='bold')\n",
        "plt.ylabel('Time (seconds)', fontsize=16)\n",
        "plt.xticks(rotation=0, fontsize=16)  # Horizontal labels with larger font\n",
        "\n",
        "# 3. Top scores by query and model\n",
        "plt.subplot(2, 2, 3)\n",
        "top_scores = results_df[results_df['rank'] == 1].copy()\n",
        "top_scores['query_label'] = top_scores['query'].map(query_labels)\n",
        "pivot_scores = top_scores.pivot(index='query_label', columns='model', values='score')\n",
        "ax = pivot_scores.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Top Result Score by Query (lower is better)', fontsize=18, fontweight='bold')\n",
        "plt.ylabel('Score', fontsize=16)\n",
        "plt.xticks(rotation=0, fontsize=16)  # Horizontal labels\n",
        "# Add value labels on bars\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.3f', fontsize=12)\n",
        "\n",
        "# 4. Dimensions vs average top score\n",
        "plt.subplot(2, 2, 4)\n",
        "model_dims = [embedding_models[m][\"dimensions\"] for m in results_df['model'].unique()]\n",
        "avg_top_scores = [results_df[(results_df['model'] == m) & (results_df['rank'] == 1)]['score'].mean()\n",
        "                 for m in results_df['model'].unique()]\n",
        "plt.scatter(model_dims, avg_top_scores, s=200)  # Larger scatter points\n",
        "for i, model in enumerate(results_df['model'].unique()):\n",
        "    plt.annotate(model, (model_dims[i], avg_top_scores[i]),\n",
        "                fontsize=14, ha='center', va='bottom')\n",
        "plt.xlabel('Embedding Dimensions', fontsize=16)\n",
        "plt.ylabel('Avg Top Score (lower is better)', fontsize=16)\n",
        "plt.title('Embedding Dimensions vs Performance', fontsize=18, fontweight='bold')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout(pad=3.0)  # Add more padding between subplots\n",
        "plt.suptitle('Embedding Model Comparison', fontsize=22, y=0.98)\n",
        "plt.subplots_adjust(top=0.92)  # Make room for the suptitle\n",
        "plt.show()\n",
        "\n",
        "# Side-by-side comparison of models across queries\n",
        "plt.figure(figsize=(15, 6))\n",
        "# Group by query label and model, get the top (rank=1) score for each\n",
        "query_model_scores = results_df_labeled[results_df_labeled['rank'] == 1].pivot(\n",
        "    index='query_label', columns='model', values='score')\n",
        "\n",
        "# Plot with custom colors and hatches for better differentiation\n",
        "ax = query_model_scores.plot(kind='bar', width=0.7, figsize=(15, 6),\n",
        "                            colormap='viridis', edgecolor='black', linewidth=1)\n",
        "\n",
        "plt.title('Best Score Comparison by Query and Model', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Query', fontsize=16)\n",
        "plt.ylabel('Score (lower is better)', fontsize=16)\n",
        "plt.xticks(rotation=0, fontsize=16)\n",
        "plt.legend(fontsize=14, title='Model', title_fontsize=14)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.3f', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c8c4a4",
      "metadata": {},
      "source": [
        "## Conclusion and Findings\n",
        "\n",
        "This notebook has evaluated three different embedding models:\n",
        "- Llama 3.2 (4096 dimensions)\n",
        "- Nomic Embed (768 dimensions) \n",
        "- HuggingFace MiniLM (384 dimensions)\n",
        "\n",
        "The visualizations help identify:\n",
        "1. Which model provides the best semantic search results\n",
        "2. Performance trade-offs between embedding dimensions and retrieval quality\n",
        "3. Response time differences between models\n",
        "\n",
        "By analyzing these metrics, you can select the most appropriate embedding model for your specific RAG application requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a866f4a5",
      "metadata": {},
      "source": [
        "## Ground Truth Setup\n",
        "\n",
        "To evaluate embedding models properly, we need ground truth data that identifies which documents are relevant for each query. This is crucial for calculating retrieval metrics like Recall, Precision, MRR, and nDCG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887112a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ground truth data for test queries\n",
        "# In a real-world scenario, this would be created by subject matter experts\n",
        "# For demonstration, we'll simulate ground truth by selecting relevant documents\n",
        "\n",
        "# Function to find relevant documents based on keyword matching\n",
        "# This is a simplified approach - in practice, use human annotators for accurate ground truth\n",
        "def create_simulated_ground_truth(documents, query, top_n=3):\n",
        "    \"\"\"Create simulated ground truth by finding documents that contain keywords from the query\"\"\"\n",
        "    # Extract keywords (simple approach: just use words with length > 3)\n",
        "    keywords = [word.lower() for word in query.split() if len(word) > 3 and word.isalnum()]\n",
        "    \n",
        "    # Score documents based on keyword presence\n",
        "    doc_scores = []\n",
        "    for i, doc in enumerate(documents):\n",
        "        score = 0\n",
        "        content_lower = doc.page_content.lower()\n",
        "        for keyword in keywords:\n",
        "            if keyword in content_lower:\n",
        "                # Add score based on frequency and position\n",
        "                score += content_lower.count(keyword) * (1 + 1/content_lower.find(keyword) if keyword in content_lower else 0)\n",
        "        doc_scores.append((i, score, doc))\n",
        "    \n",
        "    # Sort by score and get top N\n",
        "    relevant_docs = sorted(doc_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
        "    return [{\"doc_idx\": idx, \"doc_id\": f\"{doc.metadata.get('source', 'unknown')}:{doc.metadata.get('part', 'unknown')}\", \n",
        "             \"relevance\": min(score/max(1, max([s for _, s, _ in doc_scores])), 1.0)} \n",
        "            for idx, score, doc in relevant_docs if score > 0]\n",
        "\n",
        "# Update test queries with simulated ground truth\n",
        "for query_item in test_queries:\n",
        "    query_item[\"relevant_docs\"] = create_simulated_ground_truth(documents, query_item[\"query\"])\n",
        "    \n",
        "    print(f\"\\nQuery: '{query_item['query']}'\")\n",
        "    print(f\"Ground truth relevant documents:\")\n",
        "    for i, doc_info in enumerate(query_item[\"relevant_docs\"], 1):\n",
        "        doc_idx = doc_info[\"doc_idx\"]\n",
        "        print(f\"  {i}. Doc ID: {doc_info['doc_id']} (Relevance: {doc_info['relevance']:.2f})\")\n",
        "        print(f\"     Excerpt: {documents[doc_idx].page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a433f9",
      "metadata": {},
      "source": [
        "## Retrieval Metrics Implementation\n",
        "\n",
        "We'll implement several standard information retrieval metrics to evaluate the embedding models:\n",
        "\n",
        "1. **Recall@K**: The proportion of relevant documents retrieved in the top K results\n",
        "2. **Precision@K**: The proportion of the top K retrieved documents that are relevant\n",
        "3. **Mean Reciprocal Rank (MRR)**: Measures the position of the first relevant document\n",
        "4. **Normalized Discounted Cumulative Gain (nDCG)**: Measures ranking quality considering relevance scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "676129dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_retrieval_metrics(retrieved_docs, ground_truth_docs, k_values=[1, 3, 5, 10]):\n",
        "    \"\"\"\n",
        "    Calculate retrieval metrics for a single query\n",
        "    \n",
        "    Args:\n",
        "        retrieved_docs: List of retrieved documents with their scores\n",
        "        ground_truth_docs: List of relevant document IDs with relevance scores\n",
        "        k_values: K values for Precision@K and Recall@K\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary of metrics\n",
        "    \"\"\"\n",
        "    metrics = {}\n",
        "    \n",
        "    # Extract relevant doc IDs and create relevance dict\n",
        "    relevant_doc_ids = [doc[\"doc_id\"] for doc in ground_truth_docs]\n",
        "    relevance_dict = {doc[\"doc_id\"]: doc[\"relevance\"] for doc in ground_truth_docs}\n",
        "    \n",
        "    # Get retrieved doc IDs\n",
        "    retrieved_doc_ids = [doc[\"doc_id\"] for doc in retrieved_docs]\n",
        "    \n",
        "    # Calculate Precision@K and Recall@K for different K values\n",
        "    for k in k_values:\n",
        "        if k <= len(retrieved_doc_ids):\n",
        "            # Get top-k retrieved docs\n",
        "            top_k_docs = retrieved_doc_ids[:k]\n",
        "            \n",
        "            # Calculate how many relevant docs are in top-k\n",
        "            relevant_in_top_k = sum(1 for doc_id in top_k_docs if doc_id in relevant_doc_ids)\n",
        "            \n",
        "            # Precision@K = relevant retrieved / retrieved\n",
        "            precision_k = relevant_in_top_k / k\n",
        "            metrics[f'precision@{k}'] = precision_k\n",
        "            \n",
        "            # Recall@K = relevant retrieved / total relevant\n",
        "            recall_k = relevant_in_top_k / len(relevant_doc_ids) if relevant_doc_ids else 1.0\n",
        "            metrics[f'recall@{k}'] = recall_k\n",
        "    \n",
        "    # Calculate MRR (Mean Reciprocal Rank)\n",
        "    # MRR = 1 / rank of first relevant doc\n",
        "    try:\n",
        "        first_relevant_rank = next(i+1 for i, doc_id in enumerate(retrieved_doc_ids) \n",
        "                                  if doc_id in relevant_doc_ids)\n",
        "        mrr = 1.0 / first_relevant_rank\n",
        "    except StopIteration:\n",
        "        mrr = 0.0\n",
        "    metrics['mrr'] = mrr\n",
        "    \n",
        "    # Calculate nDCG@K (Normalized Discounted Cumulative Gain)\n",
        "    for k in k_values:\n",
        "        if k <= len(retrieved_doc_ids):\n",
        "            # Create relevance list for retrieved docs (0 if not in ground truth)\n",
        "            relevance_scores = [relevance_dict.get(doc_id, 0.0) for doc_id in retrieved_doc_ids[:k]]\n",
        "            \n",
        "            # Calculate DCG\n",
        "            dcg = relevance_scores[0] + sum(rel / np.log2(i+2) for i, rel in enumerate(relevance_scores[1:], 1))\n",
        "            \n",
        "            # Calculate ideal DCG (sort relevance scores in descending order)\n",
        "            ideal_relevance = sorted([rel for rel in relevance_dict.values()], reverse=True)[:k]\n",
        "            ideal_dcg = ideal_relevance[0] if ideal_relevance else 0.0\n",
        "            ideal_dcg += sum(rel / np.log2(i+2) for i, rel in enumerate(ideal_relevance[1:], 1)) if len(ideal_relevance) > 1 else 0.0\n",
        "            \n",
        "            # Calculate nDCG\n",
        "            ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0.0\n",
        "            metrics[f'ndcg@{k}'] = ndcg\n",
        "    \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53633b09",
      "metadata": {},
      "source": [
        "## Enhanced Evaluation Function\n",
        "\n",
        "Let's update our evaluation function to include the retrieval metrics we've defined. This enhanced function will track both the existing performance metrics and the new retrieval metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d2f1e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhanced_evaluate_embedding_model(model_name, embedding_model, documents, test_queries, k=10):\n",
        "    \"\"\"\n",
        "    Enhanced evaluation function that includes retrieval metrics\n",
        "    \"\"\"\n",
        "    # Time the embedding creation\n",
        "    start_time = time.time()\n",
        "    vector_store = InMemoryVectorStore.from_documents(documents, embedding_model)\n",
        "    embedding_time = time.time() - start_time\n",
        "\n",
        "    results = []\n",
        "    model_metrics = {\n",
        "        \"model\": model_name,\n",
        "        \"embedding_time\": embedding_time,\n",
        "        \"doc_count\": len(vector_store.store),\n",
        "        \"queries\": []\n",
        "    }\n",
        "\n",
        "    # Test each query\n",
        "    for test_case in test_queries:\n",
        "        query = test_case[\"query\"]\n",
        "        ground_truth = test_case[\"relevant_docs\"]\n",
        "        print(f\"\\nQuery: '{query}'\")\n",
        "\n",
        "        # Time the query execution\n",
        "        start_time = time.time()\n",
        "        search_results = vector_store.similarity_search_with_score(query, k=k)\n",
        "        query_time = time.time() - start_time\n",
        "\n",
        "        # Extract results and scores\n",
        "        retrieved_docs = []\n",
        "        for i, (doc, score) in enumerate(search_results, start=1):\n",
        "            doc_id = f\"{doc.metadata.get('source', 'unknown')}:{doc.metadata.get('part', 'unknown')}\"\n",
        "            retrieved_docs.append({\n",
        "                \"rank\": i,\n",
        "                \"doc_id\": doc_id,\n",
        "                \"score\": score,\n",
        "                \"content\": doc.page_content[:150] + \"...\" if len(doc.page_content) > 150 else doc.page_content\n",
        "            })\n",
        "            print(f\"  Result {i} (Score: {score}):\")\n",
        "            print(f\"  {doc.page_content[:150]}...\")\n",
        "            print(f\"  {'-' * 40}\")\n",
        "\n",
        "            # Add to full results for dataframe\n",
        "            results.append({\n",
        "                \"model\": model_name,\n",
        "                \"query\": query,\n",
        "                \"rank\": i,\n",
        "                \"score\": score,\n",
        "                \"doc_id\": doc_id,\n",
        "                \"content\": doc.page_content[:150] + \"...\" if len(doc.page_content) > 150 else doc.page_content,\n",
        "                \"query_time\": query_time,\n",
        "                \"is_relevant\": doc_id in [d[\"doc_id\"] for d in ground_truth]\n",
        "            })\n",
        "        \n",
        "        # Calculate retrieval metrics\n",
        "        retrieval_metrics = calculate_retrieval_metrics(retrieved_docs, ground_truth)\n",
        "        print(\"  Retrieval Metrics:\")\n",
        "        for metric, value in retrieval_metrics.items():\n",
        "            print(f\"    {metric}: {value:.4f}\")\n",
        "\n",
        "        # Calculate metrics for this query\n",
        "        query_metrics = {\n",
        "            \"query\": query,\n",
        "            \"query_time\": query_time,\n",
        "            \"top_score\": search_results[0][1] if search_results else None,\n",
        "            \"retrieved_docs\": retrieved_docs,\n",
        "            \"retrieval_metrics\": retrieval_metrics\n",
        "        }\n",
        "        model_metrics[\"queries\"].append(query_metrics)\n",
        "\n",
        "    return results, model_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ff50d04",
      "metadata": {},
      "source": [
        "## Downstream Generation Evaluation\n",
        "\n",
        "Now let's implement downstream generation evaluation. We'll use the retrieved documents to generate answers with a language model, then evaluate the quality of those answers against reference answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12d59423",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for text generation and evaluation\n",
        "%pip install rouge_score nltk bert_score sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3315d6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_ollama import Ollama\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Download NLTK data for BLEU score\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize language model for generation\n",
        "llm = Ollama(model=\"llama3.2:latest\", base_url=\"http://localhost:11434\")\n",
        "\n",
        "# Initialize sentence transformer for semantic similarity\n",
        "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Define reference answers for test queries\n",
        "reference_answers = {\n",
        "    \"how to get a policy?\": \"To get a policy, you need to use the SavePolicyBlock3 API endpoint. This requires submitting a properly formatted request with policy details to the API.\",\n",
        "    \"What is request body needed for https://{tenant_url}/Policy/SavePolicyBlock3\": \"The request body for SavePolicyBlock3 needs to include policy details like ID, name, version, and other required fields in JSON format. The exact structure depends on the policy type.\",\n",
        "    \"delete a policy\": \"To delete a policy, you need to call the deletion API with the policy ID as a parameter. This is typically done through a DELETE HTTP method to the policy endpoint.\"\n",
        "}\n",
        "\n",
        "def evaluate_generation(model_name, retrieved_docs, query, reference_answer, top_k=3):\n",
        "    \"\"\"\n",
        "    Generate an answer using the retrieved documents and evaluate it against the reference\n",
        "    \n",
        "    Args:\n",
        "        model_name: Name of the embedding model\n",
        "        retrieved_docs: List of retrieved documents\n",
        "        query: Query string\n",
        "        reference_answer: Reference answer for evaluation\n",
        "        top_k: Number of documents to use for generation\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary of generation metrics\n",
        "    \"\"\"\n",
        "    # Prepare context from top k retrieved documents\n",
        "    context = \"\\n\\n\".join([doc[\"content\"] for doc in retrieved_docs[:top_k]])\n",
        "    \n",
        "    # Create prompt\n",
        "    prompt = f\"\"\"Based on the following information, answer the question.\n",
        "\n",
        "INFORMATION:\n",
        "{context}\n",
        "\n",
        "QUESTION:\n",
        "{query}\n",
        "\n",
        "ANSWER:\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Generate answer\n",
        "        start_time = time.time()\n",
        "        generated_answer = llm.invoke(prompt)\n",
        "        generation_time = time.time() - start_time\n",
        "        \n",
        "        print(f\"\\nModel: {model_name}\")\n",
        "        print(f\"Query: '{query}'\")\n",
        "        print(f\"Generated answer: {generated_answer}\")\n",
        "        print(f\"Reference answer: {reference_answer}\")\n",
        "        \n",
        "        # Calculate ROUGE score\n",
        "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        rouge_scores = scorer.score(reference_answer, generated_answer)\n",
        "        \n",
        "        # Calculate BLEU score\n",
        "        reference_tokens = [nltk.word_tokenize(reference_answer.lower())]\n",
        "        hypothesis_tokens = nltk.word_tokenize(generated_answer.lower())\n",
        "        smoothing = SmoothingFunction().method1\n",
        "        bleu_score = sentence_bleu(reference_tokens, hypothesis_tokens, smoothing_function=smoothing)\n",
        "        \n",
        "        # Calculate semantic similarity using Sentence-BERT\n",
        "        ref_embedding = semantic_model.encode(reference_answer, convert_to_tensor=True)\n",
        "        gen_embedding = semantic_model.encode(generated_answer, convert_to_tensor=True)\n",
        "        semantic_sim = util.pytorch_cos_sim(ref_embedding, gen_embedding).item()\n",
        "        \n",
        "        # Calculate exact match score (1 if exact match, 0 otherwise)\n",
        "        exact_match = 1.0 if generated_answer.strip().lower() == reference_answer.strip().lower() else 0.0\n",
        "        \n",
        "        # Return metrics\n",
        "        metrics = {\n",
        "            \"generation_time\": generation_time,\n",
        "            \"rouge1\": rouge_scores[\"rouge1\"].fmeasure,\n",
        "            \"rouge2\": rouge_scores[\"rouge2\"].fmeasure, \n",
        "            \"rougeL\": rouge_scores[\"rougeL\"].fmeasure,\n",
        "            \"bleu\": bleu_score,\n",
        "            \"semantic_similarity\": semantic_sim,\n",
        "            \"exact_match\": exact_match,\n",
        "            \"generated_answer\": generated_answer\n",
        "        }\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error generating or evaluating answer: {e}\")\n",
        "        return {\n",
        "            \"generation_time\": 0,\n",
        "            \"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0,\n",
        "            \"bleu\": 0, \"semantic_similarity\": 0, \"exact_match\": 0,\n",
        "            \"generated_answer\": f\"Error: {str(e)}\"\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d6c7d7",
      "metadata": {},
      "source": [
        "## Complete Evaluation Framework\n",
        "\n",
        "Now we'll bring everything together to create a comprehensive evaluation framework that measures both retrieval performance and downstream generation quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10008357",
      "metadata": {},
      "outputs": [],
      "source": [
        "def comprehensive_evaluate_model(model_name, embedding_model, documents, test_queries, reference_answers, k=10):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation of embedding model, measuring both retrieval and generation metrics\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Starting Comprehensive Evaluation of {model_name} ===\")\n",
        "    \n",
        "    # Run retrieval evaluation\n",
        "    retrieval_results, retrieval_metrics = enhanced_evaluate_embedding_model(\n",
        "        model_name, embedding_model, documents, test_queries, k\n",
        "    )\n",
        "    \n",
        "    # Add generation evaluation\n",
        "    generation_results = []\n",
        "    \n",
        "    for query_metrics in retrieval_metrics[\"queries\"]:\n",
        "        query = query_metrics[\"query\"]\n",
        "        if query in reference_answers:\n",
        "            # Get reference answer\n",
        "            reference_answer = reference_answers[query]\n",
        "            \n",
        "            # Run generation evaluation\n",
        "            gen_metrics = evaluate_generation(\n",
        "                model_name, \n",
        "                query_metrics[\"retrieved_docs\"],\n",
        "                query,\n",
        "                reference_answer\n",
        "            )\n",
        "            \n",
        "            # Add to query metrics\n",
        "            query_metrics[\"generation_metrics\"] = gen_metrics\n",
        "            \n",
        "            # Add to generation results\n",
        "            generation_results.append({\n",
        "                \"model\": model_name,\n",
        "                \"query\": query,\n",
        "                \"reference\": reference_answer,\n",
        "                \"generated\": gen_metrics[\"generated_answer\"],\n",
        "                **{f\"gen_{k}\": v for k, v in gen_metrics.items() if k != \"generated_answer\"}\n",
        "            })\n",
        "    \n",
        "    # Combine results\n",
        "    all_results = {\n",
        "        \"model\": model_name,\n",
        "        \"retrieval_results\": retrieval_results,\n",
        "        \"retrieval_metrics\": retrieval_metrics,\n",
        "        \"generation_results\": generation_results\n",
        "    }\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "# Run comprehensive evaluation for all models\n",
        "comprehensive_results = []\n",
        "\n",
        "for model_name, model_info in embedding_models.items():\n",
        "    print(f\"\\n=== Comprehensive Evaluation of {model_name} (Dimensions: {model_info['dimensions']}) ===\")\n",
        "    results = comprehensive_evaluate_model(\n",
        "        model_name,\n",
        "        model_info[\"model\"],\n",
        "        documents,\n",
        "        test_queries,\n",
        "        reference_answers\n",
        "    )\n",
        "    comprehensive_results.append(results)\n",
        "\n",
        "# Create summary DataFrames\n",
        "retrieval_summary = []\n",
        "generation_summary = []\n",
        "\n",
        "for result in comprehensive_results:\n",
        "    model_name = result[\"model\"]\n",
        "    \n",
        "    # Retrieval metrics summary\n",
        "    for query_metrics in result[\"retrieval_metrics\"][\"queries\"]:\n",
        "        query = query_metrics[\"query\"]\n",
        "        retrieval_summary.append({\n",
        "            \"model\": model_name,\n",
        "            \"query\": query,\n",
        "            \"query_time\": query_metrics[\"query_time\"],\n",
        "            **query_metrics[\"retrieval_metrics\"]\n",
        "        })\n",
        "    \n",
        "    # Generation metrics summary\n",
        "    for query_metrics in result[\"retrieval_metrics\"][\"queries\"]:\n",
        "        if \"generation_metrics\" in query_metrics:\n",
        "            query = query_metrics[\"query\"]\n",
        "            gen_metrics = query_metrics[\"generation_metrics\"]\n",
        "            generation_summary.append({\n",
        "                \"model\": model_name,\n",
        "                \"query\": query,\n",
        "                \"generation_time\": gen_metrics[\"generation_time\"],\n",
        "                \"rouge1\": gen_metrics[\"rouge1\"],\n",
        "                \"rouge2\": gen_metrics[\"rouge2\"],\n",
        "                \"rougeL\": gen_metrics[\"rougeL\"],\n",
        "                \"bleu\": gen_metrics[\"bleu\"],\n",
        "                \"semantic_similarity\": gen_metrics[\"semantic_similarity\"],\n",
        "                \"exact_match\": gen_metrics[\"exact_match\"]\n",
        "            })\n",
        "\n",
        "# Convert to DataFrames\n",
        "retrieval_df = pd.DataFrame(retrieval_summary)\n",
        "generation_df = pd.DataFrame(generation_summary)\n",
        "\n",
        "print(\"\\n=== RETRIEVAL METRICS SUMMARY ===\")\n",
        "print(retrieval_df)\n",
        "\n",
        "print(\"\\n=== GENERATION METRICS SUMMARY ===\")\n",
        "print(generation_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdde6425",
      "metadata": {},
      "source": [
        "## Enhanced Visualization with Retrieval and Generation Metrics\n",
        "\n",
        "Let's create visualizations that incorporate both retrieval metrics and generation quality metrics to provide a comprehensive view of embedding model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e18eacd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations for comprehensive evaluation\n",
        "plt.figure(figsize=(20, 16))\n",
        "\n",
        "# 1. Retrieval Metrics Comparison\n",
        "plt.subplot(2, 2, 1)\n",
        "metrics_to_plot = ['precision@3', 'recall@3', 'ndcg@3', 'mrr']\n",
        "model_avg_metrics = retrieval_df.groupby('model')[metrics_to_plot].mean()\n",
        "model_avg_metrics.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Retrieval Metrics by Model', fontsize=18, fontweight='bold')\n",
        "plt.ylabel('Score (higher is better)', fontsize=16)\n",
        "plt.xticks(rotation=30, fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.ylim(0, 1.0)\n",
        "\n",
        "# 2. Generation Metrics Comparison\n",
        "plt.subplot(2, 2, 2)\n",
        "gen_metrics_to_plot = ['rouge1', 'rougeL', 'semantic_similarity']\n",
        "model_avg_gen = generation_df.groupby('model')[gen_metrics_to_plot].mean()\n",
        "model_avg_gen.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Generation Quality Metrics by Model', fontsize=18, fontweight='bold')\n",
        "plt.ylabel('Score (higher is better)', fontsize=16)\n",
        "plt.xticks(rotation=30, fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.ylim(0, 1.0)\n",
        "\n",
        "# 3. nDCG@k for different k values\n",
        "plt.subplot(2, 2, 3)\n",
        "ndcg_cols = [col for col in retrieval_df.columns if col.startswith('ndcg@')]\n",
        "model_ndcg = retrieval_df.groupby('model')[ndcg_cols].mean()\n",
        "model_ndcg.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('nDCG@k by Model', fontsize=18, fontweight='bold')\n",
        "plt.ylabel('nDCG Score', fontsize=16)\n",
        "plt.xticks(rotation=30, fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.ylim(0, 1.0)\n",
        "\n",
        "# 4. Composite Score (weighted average of retrieval and generation)\n",
        "plt.subplot(2, 2, 4)\n",
        "\n",
        "# Calculate composite scores\n",
        "composite_scores = []\n",
        "for model in retrieval_df['model'].unique():\n",
        "    # Get retrieval metrics\n",
        "    r_metrics = retrieval_df[retrieval_df['model'] == model][['precision@3', 'recall@3', 'ndcg@3', 'mrr']].mean()\n",
        "    \n",
        "    # Get generation metrics if available\n",
        "    if model in generation_df['model'].values:\n",
        "        g_metrics = generation_df[generation_df['model'] == model][['rouge1', 'rougeL', 'semantic_similarity']].mean()\n",
        "        \n",
        "        # Compute composite score (0.5 * retrieval + 0.5 * generation)\n",
        "        retrieval_score = 0.25 * (r_metrics['precision@3'] + r_metrics['recall@3'] + r_metrics['ndcg@3'] + r_metrics['mrr'])\n",
        "        generation_score = (g_metrics['rouge1'] + g_metrics['rougeL'] + g_metrics['semantic_similarity']) / 3\n",
        "        composite = 0.5 * retrieval_score + 0.5 * generation_score\n",
        "    else:\n",
        "        # Only retrieval score\n",
        "        retrieval_score = 0.25 * (r_metrics['precision@3'] + r_metrics['recall@3'] + r_metrics['ndcg@3'] + r_metrics['mrr'])\n",
        "        generation_score = 0\n",
        "        composite = retrieval_score\n",
        "    \n",
        "    composite_scores.append({\n",
        "        'model': model,\n",
        "        'retrieval_score': retrieval_score,\n",
        "        'generation_score': generation_score,\n",
        "        'composite_score': composite\n",
        "    })\n",
        "\n",
        "composite_df = pd.DataFrame(composite_scores)\n",
        "composite_df.set_index('model')[['retrieval_score', 'generation_score', 'composite_score']].plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Composite Performance Score', fontsize=18, fontweight='bold')\n",
        "plt.ylabel('Score (higher is better)', fontsize=16)\n",
        "plt.xticks(rotation=30, fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.ylim(0, 1.0)\n",
        "\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.suptitle('Comprehensive Embedding Model Evaluation', fontsize=22, y=0.98)\n",
        "plt.subplots_adjust(top=0.92)\n",
        "plt.show()\n",
        "\n",
        "# Create a final recommendation visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "composite_df = composite_df.sort_values('composite_score', ascending=False)\n",
        "ax = composite_df.plot(x='model', y='composite_score', kind='bar', color='cornflowerblue')\n",
        "plt.title('Embedding Model Recommendation (Higher is Better)', fontsize=18, fontweight='bold')\n",
        "plt.ylabel('Composite Score', fontsize=16)\n",
        "plt.xlabel('Model', fontsize=16)\n",
        "plt.xticks(rotation=30, fontsize=14)\n",
        "plt.ylim(0, 1.0)\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(composite_df['composite_score']):\n",
        "    ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=14)\n",
        "\n",
        "# Add a \"RECOMMENDED\" annotation to the best model\n",
        "best_model_idx = composite_df['composite_score'].idxmax()\n",
        "best_model = composite_df.loc[best_model_idx, 'model']\n",
        "best_score = composite_df.loc[best_model_idx, 'composite_score']\n",
        "plt.annotate('RECOMMENDED', \n",
        "             xy=(0, best_score),\n",
        "             xytext=(0, best_score + 0.15),\n",
        "             arrowprops=dict(facecolor='green', shrink=0.05),\n",
        "             fontsize=16, fontweight='bold', color='green',\n",
        "             ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5967f20e",
      "metadata": {},
      "source": [
        "## Conclusion and Model Selection\n",
        "\n",
        "After comprehensive evaluation of the embedding models using both retrieval and generation metrics, we can make an informed decision about which model performs best for our specific RAG application.\n",
        "\n",
        "The evaluation included:\n",
        "\n",
        "1. **Retrieval Performance**\n",
        "   - Precision@K and Recall@K\n",
        "   - Mean Reciprocal Rank (MRR)\n",
        "   - Normalized Discounted Cumulative Gain (nDCG)\n",
        "\n",
        "2. **Generation Quality**\n",
        "   - ROUGE scores for text similarity\n",
        "   - BLEU score for n-gram precision\n",
        "   - Semantic similarity using sentence embeddings\n",
        "   - Exact match for factual accuracy\n",
        "\n",
        "The composite score combines these metrics to provide a single measure of overall performance, helping us select the most effective embedding model for our RAG system.\n",
        "\n",
        "Based on this comprehensive evaluation, the recommended embedding model can be integrated into production systems with confidence in its performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
