{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd91d83",
   "metadata": {},
   "source": [
    "# Data Collector for YAML to JSON Conversion\n",
    "\n",
    "This notebook:\n",
    "1. Reads URLs from the OG_Dataset.csv file\n",
    "2. Downloads YAML files from those URLs\n",
    "3. Converts the YAML files to JSON format\n",
    "4. Commits the JSON files to a private Git repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3817685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "from git import Repo\n",
    "import logging\n",
    "import shutil\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01866a4c",
   "metadata": {},
   "source": [
    "## Step 1: Read the CSV file containing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ace8f8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 entries in the CSV file:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "URL",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b782cd4d-9b0e-47e6-b094-10f661393a99",
       "rows": [
        [
         "0",
         "PolicyMangement",
         "https://stoplight.io/api/v1/projects/cyberark/identity-api-reference/nodes/openapi/identity_merged_files/PolicyManagement.yaml?fromExportButton=true&snapshotType=http_service"
        ],
        [
         "1",
         "UserManagement",
         "https://stoplight.io/api/v1/projects/cyberark/identity-api-reference/nodes/openapi/identity_merged_files/UserManagement.yaml?fromExportButton=true&snapshotType=http_service"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PolicyMangement</td>\n",
       "      <td>https://stoplight.io/api/v1/projects/cyberark/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UserManagement</td>\n",
       "      <td>https://stoplight.io/api/v1/projects/cyberark/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                                                URL\n",
       "0  PolicyMangement  https://stoplight.io/api/v1/projects/cyberark/...\n",
       "1   UserManagement  https://stoplight.io/api/v1/projects/cyberark/..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "csv_path = '/workspaces/RAG_BOT/OG_Dataset.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the CSV contents\n",
    "print(f\"Found {len(df)} entries in the CSV file:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f37a1",
   "metadata": {},
   "source": [
    "## Step 2: Download YAML files and convert to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24bd1698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10810/1540392044.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  category = row[0]  # First column is the category name\n",
      "/tmp/ipykernel_10810/1540392044.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  url = row[1]       # Second column is the URL\n",
      "2025-06-07 05:56:17,155 - INFO - Processing PolicyMangement from https://stoplight.io/api/v1/projects/cyberark/identity-api-reference/nodes/openapi/identity_merged_files/PolicyManagement.yaml?fromExportButton=true&snapshotType=http_service\n",
      "2025-06-07 05:56:17,555 - INFO - Saved /workspaces/RAG_BOT/Data Collector/json_files/PolicyMangement.json\n",
      "2025-06-07 05:56:17,556 - INFO - Processing UserManagement from https://stoplight.io/api/v1/projects/cyberark/identity-api-reference/nodes/openapi/identity_merged_files/UserManagement.yaml?fromExportButton=true&snapshotType=http_service\n",
      "2025-06-07 05:56:17,555 - INFO - Saved /workspaces/RAG_BOT/Data Collector/json_files/PolicyMangement.json\n",
      "2025-06-07 05:56:17,556 - INFO - Processing UserManagement from https://stoplight.io/api/v1/projects/cyberark/identity-api-reference/nodes/openapi/identity_merged_files/UserManagement.yaml?fromExportButton=true&snapshotType=http_service\n",
      "2025-06-07 05:56:18,036 - INFO - Saved /workspaces/RAG_BOT/Data Collector/json_files/UserManagement.json\n",
      "2025-06-07 05:56:18,036 - INFO - Saved /workspaces/RAG_BOT/Data Collector/json_files/UserManagement.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 2 files\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/workspaces/RAG_BOT/Data Collector/json_files'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each URL\n",
    "json_files = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        category = row[0]  # First column is the category name\n",
    "        url = row[1]       # Second column is the URL\n",
    "        \n",
    "        logger.info(f\"Processing {category} from {url}\")\n",
    "        \n",
    "        # Download the YAML file\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        \n",
    "        # Parse YAML content\n",
    "        yaml_content = yaml.safe_load(response.text)\n",
    "        \n",
    "        # Convert to JSON\n",
    "        json_content = json.dumps(yaml_content, indent=2)\n",
    "        \n",
    "        # Save JSON to file\n",
    "        json_filename = f\"{category}.json\"\n",
    "        json_path = os.path.join(output_dir, json_filename)\n",
    "        \n",
    "        with open(json_path, 'w') as json_file:\n",
    "            json_file.write(json_content)\n",
    "        \n",
    "        logger.info(f\"Saved {json_path}\")\n",
    "        json_files.append(json_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {url}: {str(e)}\")\n",
    "\n",
    "print(f\"Successfully processed {len(json_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a43be",
   "metadata": {},
   "source": [
    "## Step 3: Configure Private Git Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "332315e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure private Git repository details\n",
    "def setup_private_repo(repo_url, auth_token):\n",
    "    \"\"\"\n",
    "    Set up credentials for private Git repository\n",
    "    \n",
    "    Args:\n",
    "        repo_url (str): URL of the private Git repository\n",
    "        auth_token (str): Authentication token for the private repository\n",
    "    \n",
    "    Returns:\n",
    "        str: The repository URL with embedded authentication token\n",
    "    \"\"\"\n",
    "    # Parse repository URL\n",
    "    parsed_url = urlparse(repo_url)\n",
    "    \n",
    "    # Construct repository URL with authentication\n",
    "    if parsed_url.scheme == \"https\":\n",
    "        # Format: https://{token}@github.com/username/repo.git\n",
    "        auth_url = f\"https://{auth_token}@{parsed_url.netloc}{parsed_url.path}\"\n",
    "    else:\n",
    "        # If not HTTPS, keep URL as is and rely on other authentication methods\n",
    "        logger.warning(\"Non-HTTPS repository URL provided. Token authentication might not work.\")\n",
    "        auth_url = repo_url\n",
    "        \n",
    "    return auth_url\n",
    "\n",
    "# Set your private repository details here\n",
    "private_repo_url = \"https://github.com/yourusername/your-private-repo.git\"  # Replace with your repository URL\n",
    "auth_token = \"your-auth-token\"  # Replace with your personal access token\n",
    "\n",
    "# Create authenticated repository URL\n",
    "authenticated_repo_url = setup_private_repo(private_repo_url, auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "584c699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_to_git(repo_path, files_to_commit, commit_message):\n",
    "    \"\"\"Commit files to a Git repository\"\"\"\n",
    "    try:\n",
    "        # Initialize repository\n",
    "        repo = Repo(repo_path)\n",
    "        \n",
    "        # Check if repo is dirty (has uncommitted changes)\n",
    "        if repo.is_dirty(untracked_files=True):\n",
    "            # Add files\n",
    "            for file_path in files_to_commit:\n",
    "                relative_path = os.path.relpath(file_path, repo_path)\n",
    "                repo.git.add(relative_path)\n",
    "            \n",
    "            # Commit changes\n",
    "            repo.git.commit('-m', commit_message)\n",
    "            logger.info(f\"Committed {len(files_to_commit)} files to repository\")\n",
    "            \n",
    "            # You could add push here if needed\n",
    "            # repo.git.push()\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            logger.info(\"No changes to commit\")\n",
    "            return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Git error: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "596580a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_to_private_repo(repo_url, files_to_commit, commit_message):\n",
    "    \"\"\"\n",
    "    Clone private repository, add files, commit and push changes\n",
    "    \n",
    "    Args:\n",
    "        repo_url (str): URL of the private Git repository with authentication token\n",
    "        files_to_commit (list): List of file paths to commit\n",
    "        commit_message (str): Commit message\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    temp_dir = '/tmp/private_repo_clone'\n",
    "    \n",
    "    try:\n",
    "        # Remove temp directory if it exists\n",
    "        if os.path.exists(temp_dir):\n",
    "            shutil.rmtree(temp_dir)\n",
    "        \n",
    "        # Clone the repository\n",
    "        logger.info(f\"Cloning private repository...\")\n",
    "        repo = Repo.clone_from(repo_url, temp_dir)\n",
    "        \n",
    "        # Create target directory in the cloned repo\n",
    "        target_dir = os.path.join(temp_dir, 'json_files')\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy files to the target directory\n",
    "        for file_path in files_to_commit:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            target_path = os.path.join(target_dir, file_name)\n",
    "            shutil.copy2(file_path, target_path)\n",
    "            logger.info(f\"Copied {file_path} to {target_path}\")\n",
    "        \n",
    "        # Add all files\n",
    "        repo.git.add(A=True)\n",
    "        \n",
    "        # Check if there are changes to commit\n",
    "        if repo.is_dirty(untracked_files=True):\n",
    "            # Commit changes\n",
    "            repo.git.commit('-m', commit_message)\n",
    "            logger.info(f\"Committed {len(files_to_commit)} files to private repository\")\n",
    "            \n",
    "            # Push changes\n",
    "            logger.info(\"Pushing changes to private repository...\")\n",
    "            repo.git.push()\n",
    "            logger.info(\"Successfully pushed changes to private repository\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            logger.info(\"No changes to commit in private repository\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error with private repository: {str(e)}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Clean up - remove temp directory\n",
    "        if os.path.exists(temp_dir):\n",
    "            shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bf5dc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 05:56:18,079 - INFO - Cloning private repository...\n",
      "2025-06-07 05:56:19,416 - INFO - Copied /workspaces/RAG_BOT/Data Collector/json_files/PolicyMangement.json to /tmp/private_repo_clone/json_files/PolicyMangement.json\n",
      "2025-06-07 05:56:19,417 - INFO - Copied /workspaces/RAG_BOT/Data Collector/json_files/UserManagement.json to /tmp/private_repo_clone/json_files/UserManagement.json\n",
      "2025-06-07 05:56:19,416 - INFO - Copied /workspaces/RAG_BOT/Data Collector/json_files/PolicyMangement.json to /tmp/private_repo_clone/json_files/PolicyMangement.json\n",
      "2025-06-07 05:56:19,417 - INFO - Copied /workspaces/RAG_BOT/Data Collector/json_files/UserManagement.json to /tmp/private_repo_clone/json_files/UserManagement.json\n",
      "2025-06-07 05:56:19,430 - INFO - No changes to commit in private repository\n",
      "2025-06-07 05:56:19,430 - INFO - No changes to commit in private repository\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to commit files to private repository\n"
     ]
    }
   ],
   "source": [
    "import datetime as date\n",
    "# Commit the files to the repository\n",
    "commit_message = \"Add converted JSON files from YAML sources - }\" + date.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "if json_files:\n",
    "    # # For local workspace repository (original approach)\n",
    "    # workspace_repo_path = '/workspaces/RAG_BOT'\n",
    "    # workspace_success = commit_to_git(workspace_repo_path, json_files, commit_message)\n",
    "    \n",
    "    # if workspace_success:\n",
    "    #     print(\"Successfully committed files to workspace repository\")\n",
    "    # else:\n",
    "    #     print(\"Failed to commit files to workspace repository\")\n",
    "    \n",
    "    # For private repository (new approach)\n",
    "    # Uncomment and fill in the details when ready to use\n",
    "    auth_token = \"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\"\n",
    "    private_repo_url = \"https://github.com/Venkata-Thrivedi-WILP/DataStore.git\"\n",
    "    authenticated_repo_url = setup_private_repo(private_repo_url, auth_token)\n",
    "    private_success = commit_to_private_repo(authenticated_repo_url, json_files, commit_message)\n",
    "    \n",
    "    if private_success:\n",
    "        print(\"Successfully committed files to private repository\")\n",
    "    else:\n",
    "        print(\"Failed to commit files to private repository\")\n",
    "else:\n",
    "    print(\"No files to commit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af462a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The notebook has:\n",
    "1. Read the CSV file with URLs\n",
    "2. Downloaded YAML files from those URLs\n",
    "3. Converted the YAML files to JSON format\n",
    "4. Saved the JSON files to the repository\n",
    "5. Provided functionality to commit the changes to both the local workspace and a private Git repository\n",
    "\n",
    "To use the private repository functionality:\n",
    "1. Replace the placeholder values in the private repository configuration cell\n",
    "2. Uncomment the private repository commit code in the final cell\n",
    "3. Run the notebook to process the files and commit them to your private repository"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
