{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ff0152",
   "metadata": {},
   "source": [
    "# API Documentation Enrichment Tool\n",
    "\n",
    "This notebook implements a data enrichment pipeline that transforms raw API endpoint documentation into a retrieval-friendly, SLM-consumable format. The enriched documentation will be better suited for RAG (Retrieval Augmented Generation) systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c250226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b2749",
   "metadata": {},
   "source": [
    "## LLM Configuration\n",
    "\n",
    "Initialize the Ollama large language model that will be used for enriching the documentation. We use a helper function to make it easy to call the model with different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d156d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "openai_api_key = getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "llm = llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    openai_api_key = openai_api_key,\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "def call_llm(prompt, model=\"llama3.2:latest\"):\n",
    "    \"\"\"\n",
    "    Call the Ollama LLM with the enrichment prompt.\n",
    "    Returns the model's response as a string.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ebe82",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up input and output directories and define the enrichment prompt template. The template instructs the SLM how to structure and enhance the API documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "815e1244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to read files from\n",
    "input_dir = \"/workspaces/RAG_BOT/ProcessedData\"\n",
    "\n",
    "# Directory to save enriched files\n",
    "output_dir = \"/workspaces/RAG_BOT/EnrichedData\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define a consistent enrichment prompt template\n",
    "enrichment_template = \"\"\"\n",
    "You are an expert API documentation assistant and retrieval-augmentation designer.  \n",
    "\n",
    "Your goal is to transform the following raw endpoint documentation into a *retrieval-friendly*, *LLM-consumable* format, should be keyword search friendly.  \n",
    "\n",
    "Your output must be structured into sections.  \n",
    "\n",
    "For each section, **strictly use only the content from the raw documentation** unless you are generating generic questions or search terms to help retrieval.  \n",
    "\n",
    "---\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Given the raw documentation, produce these sections:\n",
    "\n",
    "1. **Overview**  \n",
    "   - A concise, human-readable summary explaining the purpose and use-case of the endpoint.  \n",
    "   - Include HTTP method and path in human-friendly terms.  \n",
    "   - Explain any security/auth requirements.\n",
    "\n",
    "2. **Key Search Terms**  \n",
    "   - 5–10 relevant search keywords or phrases that someone might use to find this endpoint in a semantic search.\n",
    "\n",
    "3. **Example User Questions**  \n",
    "   - 5–10 natural-language example questions a user might ask when they need this endpoint.\n",
    "\n",
    "4. **Developer Notes**  \n",
    "   - Important details for developers (required parameters, request/response structure, error handling, security considerations).\n",
    "   - List *required fields* clearly.\n",
    "\n",
    "5. **Detailed Explanation of Availble data, Request and Response parameters**\n",
    "   - A detailed breakdown of all request and response parameters, including types, descriptions, and any constraints.\n",
    "   - try to include examples of typical values where applicable.\n",
    "\n",
    "5. **Raw Endpoint Documentation (Formatted)**  \n",
    "   - Nicely reformat and preserve the original text exactly as given (but fix any obvious formatting issues).\n",
    "\n",
    "---\n",
    "\n",
    "**Instructions for formatting output:**  \n",
    "\n",
    "- Use clear markdown headings for each section.  \n",
    "- Use bullet lists or code blocks where appropriate.  \n",
    "- Be consistent across different endpoints.  \n",
    "\n",
    "---\n",
    "\n",
    "**RAW DOCUMENTATION:**  \n",
    "\n",
    "{endpoint_text}\n",
    "\n",
    "---\n",
    "\n",
    "**Your Output:**  \n",
    "Return the fully structured markdown with all sections completed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c792343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files to process.\n"
     ]
    }
   ],
   "source": [
    "# Get all text files from the input directory\n",
    "input_files = glob.glob(os.path.join(input_dir, \"*.txt\"))\n",
    "print(f\"Found {len(input_files)} files to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5d5ca",
   "metadata": {},
   "source": [
    "## Document Processing\n",
    "\n",
    "Process each file by:\n",
    "1. Reading the content\n",
    "2. Splitting it into individual endpoint chunks\n",
    "3. Enriching each endpoint using the SLM\n",
    "4. Saving the enriched documentation to the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd840ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/3: /workspaces/RAG_BOT/ProcessedData/PolicyMangement.txt\n",
      "  - Found 9 endpoint sections in PolicyMangement.txt\n",
      "  - Processing endpoint 1/9...\n",
      "    Saved: PolicyMangement_endpoint_001.txt\n",
      "  - Processing endpoint 2/9...\n",
      "    Saved: PolicyMangement_endpoint_002.txt\n",
      "  - Processing endpoint 3/9...\n",
      "    Saved: PolicyMangement_endpoint_003.txt\n",
      "  - Processing endpoint 4/9...\n",
      "    Saved: PolicyMangement_endpoint_004.txt\n",
      "  - Processing endpoint 5/9...\n",
      "    Saved: PolicyMangement_endpoint_005.txt\n",
      "  - Processing endpoint 6/9...\n",
      "    Saved: PolicyMangement_endpoint_006.txt\n",
      "  - Processing endpoint 7/9...\n",
      "    Saved: PolicyMangement_endpoint_007.txt\n",
      "  - Processing endpoint 8/9...\n",
      "    Saved: PolicyMangement_endpoint_008.txt\n",
      "  - Processing endpoint 9/9...\n",
      "    Saved: PolicyMangement_endpoint_009.txt\n",
      "Processing file 2/3: /workspaces/RAG_BOT/ProcessedData/ApplicationManagement.txt\n",
      "  - Found 35 endpoint sections in ApplicationManagement.txt\n",
      "  - Processing endpoint 1/35...\n",
      "    Saved: ApplicationManagement_endpoint_001.txt\n",
      "  - Processing endpoint 2/35...\n",
      "    Saved: ApplicationManagement_endpoint_002.txt\n",
      "  - Processing endpoint 3/35...\n",
      "    Saved: ApplicationManagement_endpoint_003.txt\n",
      "  - Processing endpoint 4/35...\n",
      "    Saved: ApplicationManagement_endpoint_004.txt\n",
      "  - Processing endpoint 5/35...\n",
      "    Saved: ApplicationManagement_endpoint_005.txt\n",
      "  - Processing endpoint 6/35...\n",
      "    Saved: ApplicationManagement_endpoint_006.txt\n",
      "  - Processing endpoint 7/35...\n",
      "    Saved: ApplicationManagement_endpoint_007.txt\n",
      "  - Processing endpoint 8/35...\n",
      "    Saved: ApplicationManagement_endpoint_008.txt\n",
      "  - Processing endpoint 9/35...\n",
      "    Saved: ApplicationManagement_endpoint_009.txt\n",
      "  - Processing endpoint 10/35...\n",
      "    Saved: ApplicationManagement_endpoint_010.txt\n",
      "  - Processing endpoint 11/35...\n",
      "    Saved: ApplicationManagement_endpoint_011.txt\n",
      "  - Processing endpoint 12/35...\n",
      "    Saved: ApplicationManagement_endpoint_012.txt\n",
      "  - Processing endpoint 13/35...\n",
      "    Saved: ApplicationManagement_endpoint_013.txt\n",
      "  - Processing endpoint 14/35...\n",
      "    Saved: ApplicationManagement_endpoint_014.txt\n",
      "  - Processing endpoint 15/35...\n",
      "    Saved: ApplicationManagement_endpoint_015.txt\n",
      "  - Processing endpoint 16/35...\n",
      "    Saved: ApplicationManagement_endpoint_016.txt\n",
      "  - Processing endpoint 17/35...\n",
      "    Saved: ApplicationManagement_endpoint_017.txt\n",
      "  - Processing endpoint 18/35...\n",
      "    Saved: ApplicationManagement_endpoint_018.txt\n",
      "  - Processing endpoint 19/35...\n",
      "    Saved: ApplicationManagement_endpoint_019.txt\n",
      "  - Processing endpoint 20/35...\n",
      "    Saved: ApplicationManagement_endpoint_020.txt\n",
      "  - Processing endpoint 21/35...\n",
      "    Saved: ApplicationManagement_endpoint_021.txt\n",
      "  - Processing endpoint 22/35...\n",
      "    Saved: ApplicationManagement_endpoint_022.txt\n",
      "  - Processing endpoint 23/35...\n",
      "    Saved: ApplicationManagement_endpoint_023.txt\n",
      "  - Processing endpoint 24/35...\n",
      "    Saved: ApplicationManagement_endpoint_024.txt\n",
      "  - Processing endpoint 25/35...\n",
      "    Saved: ApplicationManagement_endpoint_025.txt\n",
      "  - Processing endpoint 26/35...\n",
      "    Saved: ApplicationManagement_endpoint_026.txt\n",
      "  - Processing endpoint 27/35...\n",
      "    Saved: ApplicationManagement_endpoint_027.txt\n",
      "  - Processing endpoint 28/35...\n",
      "    Saved: ApplicationManagement_endpoint_028.txt\n",
      "  - Processing endpoint 29/35...\n",
      "    Saved: ApplicationManagement_endpoint_029.txt\n",
      "  - Processing endpoint 30/35...\n",
      "    Saved: ApplicationManagement_endpoint_030.txt\n",
      "  - Processing endpoint 31/35...\n",
      "    Saved: ApplicationManagement_endpoint_031.txt\n",
      "  - Processing endpoint 32/35...\n",
      "    Saved: ApplicationManagement_endpoint_032.txt\n",
      "  - Processing endpoint 33/35...\n",
      "    Saved: ApplicationManagement_endpoint_033.txt\n",
      "  - Processing endpoint 34/35...\n",
      "    Saved: ApplicationManagement_endpoint_034.txt\n",
      "  - Processing endpoint 35/35...\n",
      "    Saved: ApplicationManagement_endpoint_035.txt\n",
      "Processing file 3/3: /workspaces/RAG_BOT/ProcessedData/UserManagement.txt\n",
      "  - Found 33 endpoint sections in UserManagement.txt\n",
      "  - Processing endpoint 1/33...\n",
      "    Saved: UserManagement_endpoint_001.txt\n",
      "  - Processing endpoint 2/33...\n",
      "    Saved: UserManagement_endpoint_002.txt\n",
      "  - Processing endpoint 3/33...\n",
      "    Saved: UserManagement_endpoint_003.txt\n",
      "  - Processing endpoint 4/33...\n",
      "    Saved: UserManagement_endpoint_004.txt\n",
      "  - Processing endpoint 5/33...\n",
      "    Saved: UserManagement_endpoint_005.txt\n",
      "  - Processing endpoint 6/33...\n",
      "    Saved: UserManagement_endpoint_006.txt\n",
      "  - Processing endpoint 7/33...\n",
      "    Saved: UserManagement_endpoint_007.txt\n",
      "  - Processing endpoint 8/33...\n",
      "    Saved: UserManagement_endpoint_008.txt\n",
      "  - Processing endpoint 9/33...\n",
      "    Saved: UserManagement_endpoint_009.txt\n",
      "  - Processing endpoint 10/33...\n",
      "    Saved: UserManagement_endpoint_010.txt\n",
      "  - Processing endpoint 11/33...\n",
      "    Saved: UserManagement_endpoint_011.txt\n",
      "  - Processing endpoint 12/33...\n",
      "    Saved: UserManagement_endpoint_012.txt\n",
      "  - Processing endpoint 13/33...\n",
      "    Saved: UserManagement_endpoint_013.txt\n",
      "  - Processing endpoint 14/33...\n",
      "    Saved: UserManagement_endpoint_014.txt\n",
      "  - Processing endpoint 15/33...\n",
      "    Saved: UserManagement_endpoint_015.txt\n",
      "  - Processing endpoint 16/33...\n",
      "    Saved: UserManagement_endpoint_016.txt\n",
      "  - Processing endpoint 17/33...\n",
      "    Saved: UserManagement_endpoint_017.txt\n",
      "  - Processing endpoint 18/33...\n",
      "    Saved: UserManagement_endpoint_018.txt\n",
      "  - Processing endpoint 19/33...\n",
      "    Saved: UserManagement_endpoint_019.txt\n",
      "  - Processing endpoint 20/33...\n",
      "    Saved: UserManagement_endpoint_020.txt\n",
      "  - Processing endpoint 21/33...\n",
      "    Saved: UserManagement_endpoint_021.txt\n",
      "  - Processing endpoint 22/33...\n",
      "    Saved: UserManagement_endpoint_022.txt\n",
      "  - Processing endpoint 23/33...\n",
      "    Saved: UserManagement_endpoint_023.txt\n",
      "  - Processing endpoint 24/33...\n",
      "    Saved: UserManagement_endpoint_024.txt\n",
      "  - Processing endpoint 25/33...\n",
      "    Saved: UserManagement_endpoint_025.txt\n",
      "  - Processing endpoint 26/33...\n",
      "    Saved: UserManagement_endpoint_026.txt\n",
      "  - Processing endpoint 27/33...\n",
      "    Saved: UserManagement_endpoint_027.txt\n",
      "  - Processing endpoint 28/33...\n",
      "    Saved: UserManagement_endpoint_028.txt\n",
      "  - Processing endpoint 29/33...\n",
      "    Saved: UserManagement_endpoint_029.txt\n",
      "  - Processing endpoint 30/33...\n",
      "    Saved: UserManagement_endpoint_030.txt\n",
      "  - Processing endpoint 31/33...\n",
      "    Saved: UserManagement_endpoint_031.txt\n",
      "  - Processing endpoint 32/33...\n",
      "    Saved: UserManagement_endpoint_032.txt\n",
      "  - Processing endpoint 33/33...\n",
      "    Saved: UserManagement_endpoint_033.txt\n"
     ]
    }
   ],
   "source": [
    "for file_idx, file_path in enumerate(input_files, 1):\n",
    "    print(f\"Processing file {file_idx}/{len(input_files)}: {file_path}\")\n",
    "    \n",
    "    # Read the file content\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        full_text = f.read()\n",
    "    \n",
    "    # Split on the known separator (adjust if it's different in your files)\n",
    "    endpoint_chunks = [chunk.strip() for chunk in full_text.split('--------------------------------------------------------------------------------') if chunk.strip()]\n",
    "    \n",
    "    print(f\"  - Found {len(endpoint_chunks)} endpoint sections in {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # Process each endpoint chunk\n",
    "    for chunk_idx, endpoint_text in enumerate(endpoint_chunks, 1):\n",
    "        print(f\"  - Processing endpoint {chunk_idx}/{len(endpoint_chunks)}...\")\n",
    "        \n",
    "        # Prepare the prompt\n",
    "        prompt = enrichment_template.format(endpoint_text=endpoint_text)\n",
    "        \n",
    "        # Get the enriched version from the sLM\n",
    "        enriched_text = call_llm(prompt)\n",
    "        \n",
    "        # Define filename using both the source file name and chunk index\n",
    "        base_filename = Path(file_path).stem\n",
    "        filename = f\"{base_filename}_endpoint_{chunk_idx:03}.txt\"\n",
    "        \n",
    "        # Save enriched text\n",
    "        with open(os.path.join(output_dir, filename), \"w\", encoding=\"utf-8\") as out_file:\n",
    "            out_file.write(enriched_text.content)\n",
    "        \n",
    "        print(f\"    Saved: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
